{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'scipy'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\u001b[39m,\u001b[39m \u001b[39mjson\u001b[39;00m\u001b[39m,\u001b[39m \u001b[39mrandom\u001b[39;00m\u001b[39m,\u001b[39m \u001b[39mmath\u001b[39;00m\u001b[39m,\u001b[39m \u001b[39mscipy\u001b[39;00m\u001b[39m,\u001b[39m \u001b[39mwandb\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmediapipe\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mmp\u001b[39;00m \n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'scipy'"
          ]
        }
      ],
      "source": [
        "import os, json, random, math, scipy, wandb\n",
        "import numpy as np\n",
        "import mediapipe as mp \n",
        "import cv2\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.notebook import tqdm\n",
        "from sklearn.model_selection import StratifiedGroupKFold \n",
        "from types import SimpleNamespace\n",
        "from pathlib import Path\n",
        "import os\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "ROWS_PER_FRAME = 543\n",
        "\n",
        "def load_relevant_data_subset(pq_path):\n",
        "    data_columns = ['x', 'y', 'z']\n",
        "    data = pd.read_parquet(pq_path, columns=data_columns)\n",
        "    n_frames = int(len(data) / ROWS_PER_FRAME)\n",
        "    data = data.values.reshape(n_frames, ROWS_PER_FRAME, len(data_columns))\n",
        "    return data.astype(np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "cfg = SimpleNamespace()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "iskaggle = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', '')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "DATA_DIR         = Path('D:/New folder/') \n",
        "TRAIN_CSV_PATH   = DATA_DIR/'train.csv'\n",
        "LANDMARK_DIR     = DATA_DIR/'train_landmark_files'\n",
        "LABEL_MAP_PATH   = DATA_DIR/'sign_to_prediction_index_map.json'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "cfg.PREPROCESS_DATA = True\n",
        "cfg.TRAIN_MODEL = True\n",
        "cfg.N_ROWS = 543\n",
        "cfg.N_DIMS = 3\n",
        "cfg.DIM_NAMES = ['x', 'y', 'z']\n",
        "cfg.SEED = 42\n",
        "cfg.NUM_CLASSES = 250\n",
        "cfg.IS_INTERACTIVE = True\n",
        "cfg.VERBOSE = 2\n",
        "cfg.INPUT_SIZE = 32\n",
        "cfg.BATCH_ALL_SIGNS_N = 4\n",
        "cfg.BATCH_SIZE = 256\n",
        "cfg.N_EPOCHS = 100\n",
        "cfg.LR_MAX = 1e-3\n",
        "cfg.N_WARMUP_EPOCHS = 0\n",
        "cfg.WD_RATIO = 0.05\n",
        "cfg.MASK_VAL = 4237"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "train = pd.read_csv(TRAIN_CSV_PATH)\n",
        "N_SAMPLES = len(train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "train['sign_ord'] = train['sign'].astype('category').cat.codes\n",
        "SIGN2ORD = train[['sign', 'sign_ord']].set_index('sign').squeeze().to_dict()\n",
        "ORD2SIGN = train[['sign_ord', 'sign']].set_index('sign_ord').squeeze().to_dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>participant_id</th>\n",
              "      <th>sequence_id</th>\n",
              "      <th>sign</th>\n",
              "      <th>sign_ord</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>train_landmark_files/26734/1000035562.parquet</td>\n",
              "      <td>26734</td>\n",
              "      <td>1000035562</td>\n",
              "      <td>blow</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>train_landmark_files/28656/1000106739.parquet</td>\n",
              "      <td>28656</td>\n",
              "      <td>1000106739</td>\n",
              "      <td>wait</td>\n",
              "      <td>232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>train_landmark_files/16069/100015657.parquet</td>\n",
              "      <td>16069</td>\n",
              "      <td>100015657</td>\n",
              "      <td>cloud</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>train_landmark_files/25571/1000210073.parquet</td>\n",
              "      <td>25571</td>\n",
              "      <td>1000210073</td>\n",
              "      <td>bird</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>train_landmark_files/62590/1000240708.parquet</td>\n",
              "      <td>62590</td>\n",
              "      <td>1000240708</td>\n",
              "      <td>owie</td>\n",
              "      <td>164</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            path  participant_id  sequence_id  \\\n",
              "0  train_landmark_files/26734/1000035562.parquet           26734   1000035562   \n",
              "1  train_landmark_files/28656/1000106739.parquet           28656   1000106739   \n",
              "2   train_landmark_files/16069/100015657.parquet           16069    100015657   \n",
              "3  train_landmark_files/25571/1000210073.parquet           25571   1000210073   \n",
              "4  train_landmark_files/62590/1000240708.parquet           62590   1000240708   \n",
              "\n",
              "    sign  sign_ord  \n",
              "0   blow        25  \n",
              "1   wait       232  \n",
              "2  cloud        48  \n",
              "3   bird        23  \n",
              "4   owie       164  "
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>participant_id</th>\n",
              "      <th>sequence_id</th>\n",
              "      <th>sign</th>\n",
              "      <th>sign_ord</th>\n",
              "      <th>fold</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>train_landmark_files/26734/1000035562.parquet</td>\n",
              "      <td>26734</td>\n",
              "      <td>1000035562</td>\n",
              "      <td>blow</td>\n",
              "      <td>25</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>train_landmark_files/28656/1000106739.parquet</td>\n",
              "      <td>28656</td>\n",
              "      <td>1000106739</td>\n",
              "      <td>wait</td>\n",
              "      <td>232</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            path  participant_id  sequence_id  \\\n",
              "0  train_landmark_files/26734/1000035562.parquet           26734   1000035562   \n",
              "1  train_landmark_files/28656/1000106739.parquet           28656   1000106739   \n",
              "\n",
              "   sign  sign_ord  fold  \n",
              "0  blow        25     0  \n",
              "1  wait       232     2  "
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "N_PARTICIPANTS = train.participant_id.nunique()\n",
        "sgkf = StratifiedGroupKFold(n_splits=7, shuffle=True, random_state=43)\n",
        "train['fold'] = -1\n",
        "for i, (train_idx, val_idx) in enumerate(sgkf.split(train.index, train.sign, train.participant_id)):\n",
        "    train.loc[val_idx, 'fold'] = i\n",
        "train.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_idxs = train.query(\"fold!=0\").index.values\n",
        "val_idxs = train.query(\"fold==0\").index.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(81735, 12742)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_idxs), len(val_idxs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(92,\n",
              " array([ 61, 185,  40,  39,  37,   0, 267, 269, 270, 409, 291, 146,  91,\n",
              "        181,  84,  17, 314, 405, 321, 375,  78, 191,  80,  81,  82,  13,\n",
              "        312, 311, 310, 415,  95,  88, 178,  87,  14, 317, 402, 318, 324,\n",
              "        308, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479,\n",
              "        480, 481, 482, 483, 484, 485, 486, 487, 488, 522, 523, 524, 525,\n",
              "        526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538,\n",
              "        539, 540, 541, 542, 502, 503, 504, 505, 506, 507, 508, 509, 510,\n",
              "        511]))"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# landmark indices in original data\n",
        "LIPS_IDXS0 = np.array([\n",
        "        61, 185, 40, 39, 37, 0, 267, 269, 270, 409,\n",
        "        291, 146, 91, 181, 84, 17, 314, 405, 321, 375,\n",
        "        78, 191, 80, 81, 82, 13, 312, 311, 310, 415,\n",
        "        95, 88, 178, 87, 14, 317, 402, 318, 324, 308,\n",
        "    ])\n",
        "LEFT_HAND_IDXS0  = np.arange(468,489)\n",
        "RIGHT_HAND_IDXS0 = np.arange(522,543)\n",
        "POSE_IDXS0       = np.arange(502, 512)\n",
        "LANDMARK_IDXS0   = np.concatenate((LIPS_IDXS0, LEFT_HAND_IDXS0, RIGHT_HAND_IDXS0, POSE_IDXS0))\n",
        "HAND_IDXS0       = np.concatenate((LEFT_HAND_IDXS0, RIGHT_HAND_IDXS0), axis=0)\n",
        "N_COLS           = LANDMARK_IDXS0.size\n",
        "N_COLS, LANDMARK_IDXS0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(42,)\n"
          ]
        }
      ],
      "source": [
        "# Landmark indices in processed data\n",
        "LIPS_IDXS       = np.argwhere(np.isin(LANDMARK_IDXS0, LIPS_IDXS0)).squeeze()\n",
        "LEFT_HAND_IDXS  = np.argwhere(np.isin(LANDMARK_IDXS0, LEFT_HAND_IDXS0)).squeeze()\n",
        "RIGHT_HAND_IDXS = np.argwhere(np.isin(LANDMARK_IDXS0, RIGHT_HAND_IDXS0)).squeeze()\n",
        "HAND_IDXS       = np.argwhere(np.isin(LANDMARK_IDXS0, HAND_IDXS0)).squeeze()\n",
        "POSE_IDXS       = np.argwhere(np.isin(LANDMARK_IDXS0, POSE_IDXS0)).squeeze()\n",
        "print(HAND_IDXS.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "class PreprocessLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self):\n",
        "        super(PreprocessLayer, self).__init__()\n",
        "        \n",
        "    def pad_edge(self, t, repeats, side):\n",
        "        if side == 'LEFT':\n",
        "            return tf.concat((tf.repeat(t[:1], repeats=repeats, axis=0), t), axis=0)\n",
        "        elif side == 'RIGHT':\n",
        "            return tf.concat((t, tf.repeat(t[-1:], repeats=repeats, axis=0)), axis=0)\n",
        "    \n",
        "    @tf.function(\n",
        "        input_signature=(tf.TensorSpec(shape=[None,cfg.N_ROWS,cfg.N_DIMS], dtype=tf.float32),),\n",
        "    )\n",
        "    def call(self, data0):\n",
        "        # Number of Frames in Video\n",
        "        N_FRAMES0 = tf.shape(data0)[0]\n",
        "        \n",
        "        # Keep only non-empty frames in data\n",
        "        frames_hands_nansum = tf.experimental.numpy.nanmean(tf.gather(data0, HAND_IDXS0, axis=1), axis=[1,2])\n",
        "        non_empty_frames_idxs = tf.where(frames_hands_nansum > 0)\n",
        "        non_empty_frames_idxs = tf.squeeze(non_empty_frames_idxs, axis=1)\n",
        "        data = tf.gather(data0, non_empty_frames_idxs, axis=0)\n",
        "        \n",
        "        non_empty_frames_idxs = tf.cast(non_empty_frames_idxs, tf.float32) \n",
        "        \n",
        "        # Number of non-empty frames\n",
        "        N_FRAMES = tf.shape(data)[0]\n",
        "        data = tf.gather(data, LANDMARK_IDXS0, axis=1)\n",
        "        \n",
        "        if N_FRAMES < cfg.INPUT_SIZE:\n",
        "            # Video fits in cfg.INPUT_SIZE\n",
        "            non_empty_frames_idxs = tf.pad(non_empty_frames_idxs, [[0, cfg.INPUT_SIZE-N_FRAMES]], constant_values=-1)\n",
        "            data = tf.pad(data, [[0, cfg.INPUT_SIZE-N_FRAMES], [0,0], [0,0]], constant_values=0)\n",
        "            data = tf.where(tf.math.is_nan(data), 0.0, data)\n",
        "            return data, non_empty_frames_idxs\n",
        "        else:\n",
        "            # Video needs to be downsampled to cfg.INPUT_SIZE\n",
        "            if N_FRAMES < cfg.INPUT_SIZE**2:\n",
        "                repeats = tf.math.floordiv(cfg.INPUT_SIZE * cfg.INPUT_SIZE, N_FRAMES0)\n",
        "                data = tf.repeat(data, repeats=repeats, axis=0)\n",
        "                non_empty_frames_idxs = tf.repeat(non_empty_frames_idxs, repeats=repeats, axis=0)\n",
        "            \n",
        "            # Pad To Multiple Of Input Size\n",
        "            pool_size = tf.math.floordiv(len(data), cfg.INPUT_SIZE)\n",
        "            if tf.math.mod(len(data), cfg.INPUT_SIZE) > 0:\n",
        "                pool_size += 1\n",
        "            if pool_size == 1:\n",
        "                pad_size = (pool_size * cfg.INPUT_SIZE) - len(data)\n",
        "            else:\n",
        "                pad_size = (pool_size * cfg.INPUT_SIZE) % len(data)\n",
        "\n",
        "            # Pad Start/End with Start/End value\n",
        "            pad_left = tf.math.floordiv(pad_size, 2) + tf.math.floordiv(cfg.INPUT_SIZE, 2)\n",
        "            pad_right = tf.math.floordiv(pad_size, 2) + tf.math.floordiv(cfg.INPUT_SIZE, 2)\n",
        "            if tf.math.mod(pad_size, 2) > 0:\n",
        "                pad_right += 1\n",
        "\n",
        "            # Pad By Concatenating Left/Right Edge Values\n",
        "            data = self.pad_edge(data, pad_left, 'LEFT')\n",
        "            data = self.pad_edge(data, pad_right, 'RIGHT')\n",
        "\n",
        "            # Pad Non Empty Frame Indices\n",
        "            non_empty_frames_idxs = self.pad_edge(non_empty_frames_idxs, pad_left, 'LEFT')\n",
        "            non_empty_frames_idxs = self.pad_edge(non_empty_frames_idxs, pad_right, 'RIGHT')\n",
        "\n",
        "            # Reshape to Mean Pool\n",
        "            data = tf.reshape(data, [cfg.INPUT_SIZE, -1, N_COLS, cfg.N_DIMS])\n",
        "            non_empty_frames_idxs = tf.reshape(non_empty_frames_idxs, [cfg.INPUT_SIZE, -1])\n",
        "\n",
        "            # Mean Pool\n",
        "            data = tf.experimental.numpy.nanmean(data, axis=1)\n",
        "            non_empty_frames_idxs = tf.experimental.numpy.nanmean(non_empty_frames_idxs, axis=1)\n",
        "\n",
        "            # Fill NaN Values With 0\n",
        "            data = tf.where(tf.math.is_nan(data), 0.0, data)\n",
        "            \n",
        "            return data, non_empty_frames_idxs\n",
        "    \n",
        "preprocess_layer = PreprocessLayer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(23, 543, 3)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample = load_relevant_data_subset(DATA_DIR/train.path[0])\n",
        "sample.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(TensorShape([32, 92, 3]),\n",
              " <tf.Tensor: shape=(32,), dtype=float32, numpy=\n",
              " array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 22., -1., -1.,\n",
              "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
              "        -1., -1., -1., -1., -1., -1.], dtype=float32)>)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data, non_empty_frames_idxs = preprocess_layer(sample)\n",
        "data.shape, non_empty_frames_idxs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "# free up RAM, delete variables as we go\n",
        "del data; del non_empty_frames_idxs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "LIPS_START = 0\n",
        "LEFT_HAND_START = LIPS_IDXS.size\n",
        "RIGHT_HAND_START = LEFT_HAND_START + LEFT_HAND_IDXS.size\n",
        "POSE_START = RIGHT_HAND_START + RIGHT_HAND_IDXS.size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_data(file_path):\n",
        "    data = load_relevant_data_subset(file_path)\n",
        "    data = preprocess_layer(data)\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_x_y():\n",
        "    # Create arrays to save data\n",
        "    X = np.zeros([N_SAMPLES, cfg.INPUT_SIZE, N_COLS, cfg.N_DIMS], dtype=np.float32)\n",
        "    y = np.zeros([N_SAMPLES], dtype=np.int32)\n",
        "    NON_EMPTY_FRAME_IDXS = np.full([N_SAMPLES, cfg.INPUT_SIZE], -1, dtype=np.float32)\n",
        "    print(NON_EMPTY_FRAME_IDXS)\n",
        "\n",
        "    for row_idx, (file_path, sign_ord) in enumerate(tqdm(train[['path', 'sign_ord']].values)):\n",
        "        if row_idx % 5000 == 0:\n",
        "            print(f'Generated {row_idx}/{N_SAMPLES}')\n",
        "\n",
        "        data, non_empty_frame_idxs = get_data(DATA_DIR/file_path)\n",
        "        X[row_idx] = data\n",
        "        y[row_idx] = sign_ord\n",
        "        NON_EMPTY_FRAME_IDXS[row_idx] = non_empty_frame_idxs\n",
        "        if np.isnan(data).sum() > 0: return data\n",
        "\n",
        "    # Save X/y\n",
        "    np.save('X.npy', X)\n",
        "    np.save('y.npy', y)\n",
        "    np.save('NON_EMPTY_FRAME_IDXS.npy', NON_EMPTY_FRAME_IDXS)\n",
        "    return X, y, NON_EMPTY_FRAME_IDXS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "cfg.PREPROCESS_DATA = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "if cfg.PREPROCESS_DATA:\n",
        "    X, y, NON_EMPTY_FRAME_IDXS = get_x_y()\n",
        "else:\n",
        "    X = np.load('X.npy')\n",
        "    y = np.load('y.npy')\n",
        "    NON_EMPTY_FRAME_IDXS = np.load('NON_EMPTY_FRAME_IDXS.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "code = pd.read_parquet('output_1.parquet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4ba12d84da9c4f99b2fab1436b59e96c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/40 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "LIPS_MEAN_X  = np.zeros([LIPS_IDXS.size], dtype=np.float32)\n",
        "LIPS_MEAN_Y  = np.zeros([LIPS_IDXS.size], dtype=np.float32)\n",
        "LIPS_STD_X   = np.zeros([LIPS_IDXS.size], dtype=np.float32)\n",
        "LIPS_STD_Y   = np.zeros([LIPS_IDXS.size], dtype=np.float32)\n",
        "for col, ll in enumerate(tqdm( np.transpose(X[:,:,LIPS_IDXS], [2,3,0,1]).reshape([LIPS_IDXS.size, cfg.N_DIMS, -1]) )):\n",
        "    for dim, l in enumerate(ll):\n",
        "        #print(dim, len(l))\n",
        "        v = l[np.nonzero(l)]\n",
        "        if dim == 0: # X\n",
        "            LIPS_MEAN_X[col] = v.mean()\n",
        "            LIPS_STD_X[col] = v.std()\n",
        "        if dim == 1: # Y\n",
        "            LIPS_MEAN_Y[col] = v.mean()\n",
        "            LIPS_STD_Y[col] = v.std()\n",
        "        \n",
        "LIPS_MEAN = np.array([LIPS_MEAN_X, LIPS_MEAN_Y]).T\n",
        "LIPS_STD = np.array([LIPS_STD_X, LIPS_STD_Y]).T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "430f6764e43342409c3b28b6235b04f2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/42 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# LEFT HAND\n",
        "LEFT_HANDS_MEAN_X = np.zeros([LEFT_HAND_IDXS.size], dtype=np.float32)\n",
        "LEFT_HANDS_MEAN_Y = np.zeros([LEFT_HAND_IDXS.size], dtype=np.float32)\n",
        "LEFT_HANDS_STD_X = np.zeros([LEFT_HAND_IDXS.size], dtype=np.float32)\n",
        "LEFT_HANDS_STD_Y = np.zeros([LEFT_HAND_IDXS.size], dtype=np.float32)\n",
        "# RIGHT HAND\n",
        "RIGHT_HANDS_MEAN_X = np.zeros([RIGHT_HAND_IDXS.size], dtype=np.float32)\n",
        "RIGHT_HANDS_MEAN_Y = np.zeros([RIGHT_HAND_IDXS.size], dtype=np.float32)\n",
        "RIGHT_HANDS_STD_X = np.zeros([RIGHT_HAND_IDXS.size], dtype=np.float32)\n",
        "RIGHT_HANDS_STD_Y = np.zeros([RIGHT_HAND_IDXS.size], dtype=np.float32)\n",
        "\n",
        "for col, ll in enumerate(tqdm( np.transpose(X[:,:,HAND_IDXS], [2,3,0,1]).reshape([HAND_IDXS.size, cfg.N_DIMS, -1]))):\n",
        "    for dim, l in enumerate(ll):\n",
        "        v = l[np.nonzero(l)]\n",
        "        if dim == 0: # X\n",
        "            if col < RIGHT_HAND_IDXS.size: # LEFT HAND\n",
        "                LEFT_HANDS_MEAN_X[col] = v.mean()\n",
        "                LEFT_HANDS_STD_X[col] = v.std()\n",
        "            else:\n",
        "                RIGHT_HANDS_MEAN_X[col - LEFT_HAND_IDXS.size] = v.mean()\n",
        "                RIGHT_HANDS_STD_X[col - LEFT_HAND_IDXS.size] = v.std()\n",
        "        if dim == 1: # Y\n",
        "            if col < RIGHT_HAND_IDXS.size: # LEFT HAND\n",
        "                LEFT_HANDS_MEAN_Y[col] = v.mean()\n",
        "                LEFT_HANDS_STD_Y[col] = v.std()\n",
        "            else: # RIGHT HAND\n",
        "                RIGHT_HANDS_MEAN_Y[col - LEFT_HAND_IDXS.size] = v.mean()\n",
        "                RIGHT_HANDS_STD_Y[col - LEFT_HAND_IDXS.size] = v.std()\n",
        "        \n",
        "LEFT_HANDS_MEAN = np.array([LEFT_HANDS_MEAN_X, LEFT_HANDS_MEAN_Y]).T\n",
        "LEFT_HANDS_STD = np.array([LEFT_HANDS_STD_X, LEFT_HANDS_STD_Y]).T\n",
        "RIGHT_HANDS_MEAN = np.array([RIGHT_HANDS_MEAN_X, RIGHT_HANDS_MEAN_Y]).T\n",
        "RIGHT_HANDS_STD = np.array([RIGHT_HANDS_STD_X, RIGHT_HANDS_STD_Y]).T\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "57cc49b93f72468390649d7bd5f1a37f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# POSE\n",
        "POSE_MEAN_X = np.zeros([POSE_IDXS.size], dtype=np.float32)\n",
        "POSE_MEAN_Y = np.zeros([POSE_IDXS.size], dtype=np.float32)\n",
        "POSE_STD_X = np.zeros([POSE_IDXS.size], dtype=np.float32)\n",
        "POSE_STD_Y = np.zeros([POSE_IDXS.size], dtype=np.float32)\n",
        "\n",
        "for col, ll in enumerate(tqdm( np.transpose(X[:,:,POSE_IDXS], [2,3,0,1]).reshape([POSE_IDXS.size, cfg.N_DIMS, -1]) )):\n",
        "    for dim, l in enumerate(ll):\n",
        "        v = l[np.nonzero(l)]\n",
        "        if dim == 0: # X\n",
        "            POSE_MEAN_X[col] = v.mean()\n",
        "            POSE_STD_X[col] = v.std()\n",
        "        if dim == 1: # Y\n",
        "            POSE_MEAN_Y[col] = v.mean()\n",
        "            POSE_STD_Y[col] = v.std()\n",
        "        \n",
        "POSE_MEAN = np.array([POSE_MEAN_X, POSE_MEAN_Y]).T\n",
        "POSE_STD = np.array([POSE_STD_X, POSE_STD_Y]).T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Custom sampler to get a batch containing N times all signs\n",
        "def get_train_batch_all_signs(X, y, NON_EMPTY_FRAME_IDXS, n=cfg.BATCH_ALL_SIGNS_N):\n",
        "    # Arrays to store batch in\n",
        "    X_batch = np.zeros([cfg.NUM_CLASSES*n, cfg.INPUT_SIZE, N_COLS, cfg.N_DIMS], dtype=np.float32)\n",
        "    y_batch = np.arange(0, cfg.NUM_CLASSES, step=1/n, dtype=np.float32).astype(np.int64)\n",
        "    non_empty_frame_idxs_batch = np.zeros([cfg.NUM_CLASSES*n, cfg.INPUT_SIZE], dtype=np.float32)\n",
        "    \n",
        "    # Dictionary mapping ordinally encoded sign to corresponding sample indices\n",
        "    CLASS2IDXS = {}\n",
        "    for i in range(cfg.NUM_CLASSES):\n",
        "        CLASS2IDXS[i] = np.argwhere(y == i).squeeze().astype(np.int32)\n",
        "            \n",
        "    while True:\n",
        "        # Fill batch arrays\n",
        "        for i in range(cfg.NUM_CLASSES):\n",
        "            idxs = np.random.choice(CLASS2IDXS[i], n)\n",
        "            X_batch[i*n:(i+1)*n] = X[idxs]\n",
        "            non_empty_frame_idxs_batch[i*n:(i+1)*n] = NON_EMPTY_FRAME_IDXS[idxs]\n",
        "        \n",
        "        yield { 'frames': X_batch, 'non_empty_frame_idxs': non_empty_frame_idxs_batch }, y_batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'frames': array([[[[ 4.99982625e-01,  6.28041029e-01, -1.33824383e-03],\n",
            "         [ 5.02689958e-01,  6.23699784e-01, -1.05463741e-02],\n",
            "         [ 5.07382393e-01,  6.19037449e-01, -2.02609431e-02],\n",
            "         ...,\n",
            "         [-2.28759591e-02,  1.24664307e+00, -1.19047284e+00],\n",
            "         [ 7.16434181e-01,  7.56501794e-01, -1.79123425e+00],\n",
            "         [-1.72850001e-03,  1.22810888e+00, -1.03676283e+00]],\n",
            "\n",
            "        [[ 4.97573704e-01,  6.28199339e-01, -2.01072684e-03],\n",
            "         [ 5.00419557e-01,  6.23996854e-01, -1.13050025e-02],\n",
            "         [ 5.05087316e-01,  6.19480789e-01, -2.10849196e-02],\n",
            "         ...,\n",
            "         [-1.88705344e-02,  1.24508464e+00, -9.56571579e-01],\n",
            "         [ 7.25015402e-01,  7.37008631e-01, -1.88841856e+00],\n",
            "         [-2.94903730e-04,  1.22672141e+00, -8.08077157e-01]],\n",
            "\n",
            "        [[ 4.91760552e-01,  6.29251301e-01, -3.33652599e-03],\n",
            "         [ 4.94506329e-01,  6.25109851e-01, -1.25338417e-02],\n",
            "         [ 4.99136060e-01,  6.20558977e-01, -2.21156944e-02],\n",
            "         ...,\n",
            "         [-1.42107932e-02,  1.24758303e+00, -9.87402201e-01],\n",
            "         [ 7.25502789e-01,  7.15560794e-01, -1.81795263e+00],\n",
            "         [ 8.17970559e-03,  1.22913384e+00, -8.33445847e-01]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         ...,\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
            "\n",
            "        [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         ...,\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
            "\n",
            "        [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         ...,\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00]]],\n",
            "\n",
            "\n",
            "       [[[ 3.57100904e-01,  4.34873164e-01,  1.92805603e-02],\n",
            "         [ 3.57169628e-01,  4.31255430e-01,  8.18811264e-03],\n",
            "         [ 3.59404087e-01,  4.27539557e-01, -5.24536707e-03],\n",
            "         ...,\n",
            "         [ 2.93055296e-01,  6.92307413e-01, -2.38888431e+00],\n",
            "         [ 9.13546741e-01,  1.39306939e+00, -7.61879802e-01],\n",
            "         [ 2.89569110e-01,  7.13402331e-01, -2.23059940e+00]],\n",
            "\n",
            "        [[ 3.54937315e-01,  4.38968331e-01,  2.02091597e-02],\n",
            "         [ 3.54316235e-01,  4.35427666e-01,  8.96508526e-03],\n",
            "         [ 3.56039643e-01,  4.31866229e-01, -4.67008259e-03],\n",
            "         ...,\n",
            "         [ 3.25905025e-01,  6.81392252e-01, -2.28618264e+00],\n",
            "         [ 9.02011752e-01,  1.39539075e+00, -7.23164737e-01],\n",
            "         [ 3.18627894e-01,  7.02721536e-01, -2.14838004e+00]],\n",
            "\n",
            "        [[ 3.55452359e-01,  4.41005856e-01,  2.02491917e-02],\n",
            "         [ 3.55810940e-01,  4.37782228e-01,  8.95098038e-03],\n",
            "         [ 3.58407527e-01,  4.34525013e-01, -4.64692619e-03],\n",
            "         ...,\n",
            "         [ 3.54910225e-01,  6.56191170e-01, -2.48557854e+00],\n",
            "         [ 9.04269516e-01,  1.39588678e+00, -7.79993236e-01],\n",
            "         [ 3.46463025e-01,  6.79935634e-01, -2.32424712e+00]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         ...,\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
            "\n",
            "        [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         ...,\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
            "\n",
            "        [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         ...,\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00]]],\n",
            "\n",
            "\n",
            "       [[[ 4.43120986e-01,  4.50183839e-01,  1.36529477e-02],\n",
            "         [ 4.45767462e-01,  4.46111411e-01,  6.83044840e-04],\n",
            "         [ 4.50946152e-01,  4.42232311e-01, -1.40634608e-02],\n",
            "         ...,\n",
            "         [ 1.42565340e-01,  6.09148920e-01, -3.20554209e+00],\n",
            "         [ 1.01194429e+00,  1.39121532e+00, -1.42320538e+00],\n",
            "         [ 1.69382721e-01,  6.55770957e-01, -2.93427038e+00]],\n",
            "\n",
            "        [[ 4.44688559e-01,  4.54689592e-01,  1.60830226e-02],\n",
            "         [ 4.47779298e-01,  4.50923175e-01,  2.85029341e-03],\n",
            "         [ 4.53166962e-01,  4.47464585e-01, -1.18866516e-02],\n",
            "         ...,\n",
            "         [ 1.70481950e-01,  5.97567081e-01, -3.19697523e+00],\n",
            "         [ 1.00701714e+00,  1.38945103e+00, -1.44043291e+00],\n",
            "         [ 1.93727732e-01,  6.44405663e-01, -2.92969251e+00]],\n",
            "\n",
            "        [[ 4.43161041e-01,  4.60403383e-01,  1.81904715e-02],\n",
            "         [ 4.45892900e-01,  4.56836313e-01,  4.67927288e-03],\n",
            "         [ 4.51067597e-01,  4.53467220e-01, -1.01524657e-02],\n",
            "         ...,\n",
            "         [ 1.22379281e-01,  6.72767401e-01, -3.31389809e+00],\n",
            "         [ 1.00695312e+00,  1.38920224e+00, -1.41849804e+00],\n",
            "         [ 1.38246417e-01,  7.73009539e-01, -3.00822568e+00]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         ...,\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
            "\n",
            "        [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         ...,\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
            "\n",
            "        [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         ...,\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00]]],\n",
            "\n",
            "\n",
            "       ...,\n",
            "\n",
            "\n",
            "       [[[ 4.14892584e-01,  4.58446622e-01, -3.15675214e-02],\n",
            "         [ 4.19807762e-01,  4.53467786e-01, -3.65006328e-02],\n",
            "         [ 4.28341776e-01,  4.48016226e-01, -4.27250788e-02],\n",
            "         ...,\n",
            "         [ 2.54110247e-01,  4.76488620e-01, -2.78220510e+00],\n",
            "         [ 1.04217637e+00,  1.40561712e+00, -6.29314721e-01],\n",
            "         [ 2.42734894e-01,  5.01845598e-01, -2.67639089e+00]],\n",
            "\n",
            "        [[ 4.16211635e-01,  4.58811879e-01, -3.37013938e-02],\n",
            "         [ 4.21011686e-01,  4.54071552e-01, -3.80574949e-02],\n",
            "         [ 4.29669231e-01,  4.48511779e-01, -4.38486412e-02],\n",
            "         ...,\n",
            "         [ 2.81984836e-01,  5.06827056e-01, -2.65848660e+00],\n",
            "         [ 1.04073608e+00,  1.41032338e+00, -6.51724279e-01],\n",
            "         [ 2.56038338e-01,  5.19073546e-01, -2.62001061e+00]],\n",
            "\n",
            "        [[ 4.15631056e-01,  4.61304367e-01, -3.41660939e-02],\n",
            "         [ 4.20352161e-01,  4.56204712e-01, -3.86615619e-02],\n",
            "         [ 4.28747654e-01,  4.50343370e-01, -4.46710885e-02],\n",
            "         ...,\n",
            "         [ 2.31118634e-01,  5.25426567e-01, -2.64089108e+00],\n",
            "         [ 1.03998780e+00,  1.41013885e+00, -6.61365211e-01],\n",
            "         [ 2.15681538e-01,  5.35514951e-01, -2.59107089e+00]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         ...,\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
            "\n",
            "        [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         ...,\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
            "\n",
            "        [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         ...,\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00]]],\n",
            "\n",
            "\n",
            "       [[[ 3.36703151e-01,  4.60789800e-01,  1.92472879e-02],\n",
            "         [ 3.41292441e-01,  4.59003150e-01,  7.32868491e-03],\n",
            "         [ 3.47252131e-01,  4.57287461e-01, -5.55123854e-03],\n",
            "         ...,\n",
            "         [ 6.02289326e-02,  1.17998040e+00, -1.57407737e+00],\n",
            "         [ 5.94209015e-01,  6.30885839e-01, -2.04890418e+00],\n",
            "         [ 6.63867593e-02,  1.15520251e+00, -1.39250076e+00]],\n",
            "\n",
            "        [[ 3.16882491e-01,  4.76181805e-01,  2.26031467e-02],\n",
            "         [ 3.22110146e-01,  4.75038648e-01,  1.01324962e-02],\n",
            "         [ 3.28633487e-01,  4.73902702e-01, -3.79875558e-03],\n",
            "         ...,\n",
            "         [-9.25626140e-03,  1.19331837e+00, -1.50908852e+00],\n",
            "         [ 5.95137417e-01,  6.92759275e-01, -1.62291312e+00],\n",
            "         [ 6.01945166e-03,  1.17072010e+00, -1.35278594e+00]],\n",
            "\n",
            "        [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         ...,\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         ...,\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
            "\n",
            "        [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         ...,\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
            "\n",
            "        [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         ...,\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00]]],\n",
            "\n",
            "\n",
            "       [[[ 3.75432491e-01,  5.31823397e-01, -1.03649031e-02],\n",
            "         [ 3.76261771e-01,  5.25574088e-01, -2.09155343e-02],\n",
            "         [ 3.79897863e-01,  5.18414736e-01, -3.25906314e-02],\n",
            "         ...,\n",
            "         [ 2.61139870e-03,  1.44572210e+00, -8.54127586e-01],\n",
            "         [ 6.77614450e-01,  4.73510683e-01, -1.98230386e+00],\n",
            "         [ 2.29340792e-02,  1.41327322e+00, -6.91741586e-01]],\n",
            "\n",
            "        [[ 3.75920415e-01,  5.30336976e-01, -1.35166096e-02],\n",
            "         [ 3.77153903e-01,  5.24009883e-01, -2.37528477e-02],\n",
            "         [ 3.81030619e-01,  5.17039299e-01, -3.46826911e-02],\n",
            "         ...,\n",
            "         [ 2.60054716e-03,  1.31997168e+00, -5.81325412e-01],\n",
            "         [ 7.08459735e-01,  4.90053535e-01, -2.02821422e+00],\n",
            "         [ 2.34847721e-02,  1.30112815e+00, -4.84080493e-01]],\n",
            "\n",
            "        [[ 3.76729339e-01,  5.30933857e-01, -1.34573085e-02],\n",
            "         [ 3.78061116e-01,  5.24436593e-01, -2.37436816e-02],\n",
            "         [ 3.81966561e-01,  5.17275155e-01, -3.49950567e-02],\n",
            "         ...,\n",
            "         [-3.10612321e-02,  1.33817399e+00,  4.55211699e-01],\n",
            "         [ 7.40867317e-01,  4.89076108e-01, -2.27705836e+00],\n",
            "         [-7.79663725e-03,  1.32232463e+00,  5.45439065e-01]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         ...,\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
            "\n",
            "        [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         ...,\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
            "\n",
            "        [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         ...,\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00]]]],\n",
            "      dtype=float32), 'non_empty_frame_idxs': array([[ 0.,  1.,  2., ..., -1., -1., -1.],\n",
            "       [ 0.,  2.,  3., ..., -1., -1., -1.],\n",
            "       [ 0.,  1.,  3., ..., -1., -1., -1.],\n",
            "       ...,\n",
            "       [ 0.,  1.,  2., ..., -1., -1., -1.],\n",
            "       [ 0.,  9., -1., ..., -1., -1., -1.],\n",
            "       [ 0.,  1.,  2., ..., -1., -1., -1.]], dtype=float32)}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(dict_keys(['frames', 'non_empty_frame_idxs']), (1000, 32, 92, 3))"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dummy_dataset = get_train_batch_all_signs(X, y, NON_EMPTY_FRAME_IDXS)\n",
        "X_batch, y_batch = next(dummy_dataset)\n",
        "print(X_batch)\n",
        "X_batch.keys(), X_batch['frames'].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Epsilon value for layer normalisation\n",
        "LAYER_NORM_EPS = 1e-6\n",
        "\n",
        "# Dense layer units for landmarks\n",
        "LIPS_UNITS = 384\n",
        "HANDS_UNITS = 384\n",
        "POSE_UNITS = 384\n",
        "# final embedding and transformer embedding size\n",
        "UNITS = 384\n",
        "\n",
        "# Transformer\n",
        "NUM_BLOCKS = 2\n",
        "MLP_RATIO = 2\n",
        "\n",
        "# Dropout\n",
        "EMBEDDING_DROPOUT = 0.00\n",
        "MLP_DROPOUT_RATIO = 0.30\n",
        "CLASSIFIER_DROPOUT_RATIO = 0.10\n",
        "\n",
        "# Initiailizers\n",
        "INIT_HE_UNIFORM = tf.keras.initializers.he_uniform\n",
        "INIT_GLOROT_UNIFORM = tf.keras.initializers.glorot_uniform\n",
        "INIT_ZEROS = tf.keras.initializers.constant(0.0)\n",
        "# Activations\n",
        "GELU = tf.keras.activations.gelu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "def scaled_dot_product(q,k,v, softmax, attention_mask):\n",
        "    #calculates Q . K(transpose)\n",
        "    qkt = tf.matmul(q,k,transpose_b=True)\n",
        "    #caculates scaling factor\n",
        "    dk = tf.math.sqrt(tf.cast(q.shape[-1],dtype=tf.float32))\n",
        "    scaled_qkt = qkt/dk\n",
        "    softmax = softmax(scaled_qkt, mask=attention_mask)\n",
        "    \n",
        "    z = tf.matmul(softmax,v)\n",
        "    #shape: (m,Tx,depth), same shape as q,k,v\n",
        "    return z\n",
        "\n",
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self,d_model,num_of_heads):\n",
        "        super(MultiHeadAttention,self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.num_of_heads = num_of_heads\n",
        "        self.depth = d_model//num_of_heads\n",
        "        self.wq = [tf.keras.layers.Dense(self.depth) for i in range(num_of_heads)]\n",
        "        self.wk = [tf.keras.layers.Dense(self.depth) for i in range(num_of_heads)]\n",
        "        self.wv = [tf.keras.layers.Dense(self.depth) for i in range(num_of_heads)]\n",
        "        self.wo = tf.keras.layers.Dense(d_model)\n",
        "        self.softmax = tf.keras.layers.Softmax()\n",
        "        \n",
        "    def call(self,x, attention_mask):\n",
        "        \n",
        "        multi_attn = []\n",
        "        for i in range(self.num_of_heads):\n",
        "            Q = self.wq[i](x)\n",
        "            K = self.wk[i](x)\n",
        "            V = self.wv[i](x)\n",
        "            multi_attn.append(scaled_dot_product(Q,K,V, self.softmax, attention_mask))\n",
        "            \n",
        "        multi_head = tf.concat(multi_attn,axis=-1)\n",
        "        multi_head_attention = self.wo(multi_head)\n",
        "        return multi_head_attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Transformer(tf.keras.Model):\n",
        "    def __init__(self, num_blocks):\n",
        "        super(Transformer, self).__init__(name='transformer')\n",
        "        self.num_blocks = num_blocks\n",
        "    \n",
        "    def build(self, input_shape):\n",
        "        self.ln_1s = []\n",
        "        self.mhas = []\n",
        "        self.ln_2s = []\n",
        "        self.mlps = []\n",
        "        # Make Transformer Blocks\n",
        "        for i in range(self.num_blocks):\n",
        "            # First Layer Normalisation\n",
        "            self.ln_1s.append(tf.keras.layers.LayerNormalization(epsilon=LAYER_NORM_EPS))\n",
        "            # Multi Head Attention\n",
        "            self.mhas.append(MultiHeadAttention(UNITS, 12))\n",
        "            # Second Layer Normalisation\n",
        "            self.ln_2s.append(tf.keras.layers.LayerNormalization(epsilon=LAYER_NORM_EPS))\n",
        "            # Multi Layer Perception\n",
        "            self.mlps.append(tf.keras.Sequential([\n",
        "                tf.keras.layers.Dense(UNITS * MLP_RATIO, activation=GELU, kernel_initializer=INIT_GLOROT_UNIFORM),\n",
        "                tf.keras.layers.Dropout(MLP_DROPOUT_RATIO),\n",
        "                tf.keras.layers.Dense(UNITS, kernel_initializer=INIT_HE_UNIFORM),\n",
        "            ]))\n",
        "        \n",
        "    def call(self, x, attention_mask):\n",
        "        # Iterate input over transformer blocks\n",
        "        for ln_1, mha, ln_2, mlp in zip(self.ln_1s, self.mhas, self.ln_2s, self.mlps):\n",
        "            x1 = ln_1(x)\n",
        "            attention_output = mha(x1, attention_mask)\n",
        "            x2 = x1 + attention_output\n",
        "            x3 = ln_2(x2)\n",
        "            x3 = mlp(x3)\n",
        "            x = x3 + x2\n",
        "    \n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "class LandmarkEmbedding(tf.keras.Model):\n",
        "    def __init__(self, units, name):\n",
        "        super(LandmarkEmbedding, self).__init__(name=f'{name}_embedding')\n",
        "        self.units = units\n",
        "        \n",
        "    def build(self, input_shape):\n",
        "        # Embedding for missing landmark in frame, initizlied with zeros\n",
        "        self.empty_embedding = self.add_weight(\n",
        "            name=f'{self.name}_empty_embedding',\n",
        "            shape=[self.units],\n",
        "            initializer=INIT_ZEROS,\n",
        "        )\n",
        "        # Embedding\n",
        "        self.dense = tf.keras.Sequential([\n",
        "            tf.keras.layers.Dense(self.units, name=f'{self.name}_dense_1', use_bias=False, kernel_initializer=INIT_GLOROT_UNIFORM, activation=GELU),\n",
        "            tf.keras.layers.Dense(self.units, name=f'{self.name}_dense_2', use_bias=False, kernel_initializer=INIT_HE_UNIFORM),\n",
        "        ], name=f'{self.name}_dense')\n",
        "\n",
        "    def call(self, x):\n",
        "        return tf.where(\n",
        "                # Checks whether landmark is missing in frame\n",
        "                tf.reduce_sum(x, axis=2, keepdims=True) == 0,\n",
        "                # If so, the empty embedding is used\n",
        "                self.empty_embedding,\n",
        "                # Otherwise the landmark data is embedded\n",
        "                self.dense(x),\n",
        "            )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CustomEmbedding(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(CustomEmbedding, self).__init__()\n",
        "        \n",
        "    def get_diffs(self, l):\n",
        "        S = l.shape[2]\n",
        "        other = tf.expand_dims(l, 3)\n",
        "        other = tf.repeat(other, S, axis=3)\n",
        "        other = tf.transpose(other, [0,1,3,2])\n",
        "        diffs = tf.expand_dims(l, 3) - other\n",
        "        diffs = tf.reshape(diffs, [-1, cfg.INPUT_SIZE, S*S])\n",
        "        return diffs\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        # Positional Embedding, initialized with zeros\n",
        "        self.positional_embedding = tf.keras.layers.Embedding(cfg.INPUT_SIZE+1, UNITS, embeddings_initializer=INIT_ZEROS)\n",
        "        # Embedding layer for Landmarks\n",
        "        self.lips_embedding = LandmarkEmbedding(LIPS_UNITS, 'lips')\n",
        "        self.left_hand_embedding = LandmarkEmbedding(HANDS_UNITS, 'left_hand')\n",
        "        self.right_hand_embedding = LandmarkEmbedding(HANDS_UNITS, 'right_hand')\n",
        "        self.pose_embedding = LandmarkEmbedding(POSE_UNITS, 'pose')\n",
        "        # Landmark Weights\n",
        "        self.landmark_weights = tf.Variable(tf.zeros([4], dtype=tf.float32), name='landmark_weights')\n",
        "        # Fully Connected Layers for combined landmarks\n",
        "        self.fc = tf.keras.Sequential([\n",
        "            tf.keras.layers.Dense(UNITS, name='fully_connected_1', use_bias=False, kernel_initializer=INIT_GLOROT_UNIFORM, activation=GELU),\n",
        "            tf.keras.layers.Dense(UNITS, name='fully_connected_2', use_bias=False, kernel_initializer=INIT_HE_UNIFORM),\n",
        "        ], name='fc')\n",
        "\n",
        "\n",
        "    def call(self, lips0, left_hand0, right_hand0, pose0, non_empty_frame_idxs, training=False):\n",
        "        # Lips\n",
        "        lips_embedding = self.lips_embedding(lips0)\n",
        "        # Left Hand\n",
        "        left_hand_embedding = self.left_hand_embedding(left_hand0)\n",
        "        # Right Hand\n",
        "        right_hand_embedding = self.right_hand_embedding(right_hand0)\n",
        "        # Pose\n",
        "        pose_embedding = self.pose_embedding(pose0)\n",
        "        # Merge Embeddings of all landmarks with mean pooling\n",
        "        x = tf.stack((lips_embedding, left_hand_embedding, right_hand_embedding, pose_embedding), axis=3)\n",
        "        # Merge Landmarks with trainable attention weights\n",
        "        x = x * tf.nn.softmax(self.landmark_weights)\n",
        "        x = tf.reduce_sum(x, axis=3)\n",
        "        # Fully Connected Layers\n",
        "        x = self.fc(x)\n",
        "        # Add Positional Embedding\n",
        "        normalised_non_empty_frame_idxs = tf.where(\n",
        "            tf.math.equal(non_empty_frame_idxs, -1.0),\n",
        "            cfg.INPUT_SIZE,\n",
        "            tf.cast(\n",
        "                non_empty_frame_idxs / tf.reduce_max(non_empty_frame_idxs, axis=1, keepdims=True) * cfg.INPUT_SIZE,\n",
        "                tf.int32,\n",
        "            ),\n",
        "        )\n",
        "        x = x + self.positional_embedding(normalised_non_empty_frame_idxs)\n",
        "        \n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_lr_metric(optimizer):\n",
        "    def lr(y_true, y_pred):\n",
        "        return optimizer.lr\n",
        "    return lr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_model():\n",
        "    # Inputs\n",
        "    frames = tf.keras.layers.Input([cfg.INPUT_SIZE, N_COLS, cfg.N_DIMS], dtype=tf.float32, name='frames')\n",
        "    non_empty_frame_idxs = tf.keras.layers.Input([cfg.INPUT_SIZE], dtype=tf.float32, name='non_empty_frame_idxs')\n",
        "    # Padding Mask\n",
        "    mask = tf.cast(tf.math.not_equal(non_empty_frame_idxs, -1), tf.float32)\n",
        "    mask = tf.expand_dims(mask, axis=2)\n",
        "    \n",
        "    x = frames\n",
        "    x = tf.slice(x, [0,0,0,0], [-1,cfg.INPUT_SIZE, N_COLS, 2])\n",
        "    # LIPS\n",
        "    lips = tf.slice(x, [0,0,LIPS_START,0], [-1,cfg.INPUT_SIZE, 40, 2])\n",
        "    lips = tf.where(\n",
        "            tf.math.equal(lips, 0.0),\n",
        "            0.0,\n",
        "            (lips - LIPS_MEAN) / LIPS_STD,\n",
        "        )\n",
        "    lips = tf.reshape(lips, [-1, cfg.INPUT_SIZE, 40*2])\n",
        "    # LEFT HAND\n",
        "    left_hand = tf.slice(x, [0,0,40,0], [-1,cfg.INPUT_SIZE, 21, 2])\n",
        "    left_hand = tf.where(\n",
        "            tf.math.equal(left_hand, 0.0),\n",
        "            0.0,\n",
        "            (left_hand - LEFT_HANDS_MEAN) / LEFT_HANDS_STD,\n",
        "        )\n",
        "    left_hand = tf.reshape(left_hand, [-1, cfg.INPUT_SIZE, 21*2])\n",
        "    # RIGHT HAND\n",
        "    right_hand = tf.slice(x, [0,0,61,0], [-1,cfg.INPUT_SIZE, 21, 2])\n",
        "    right_hand = tf.where(\n",
        "            tf.math.equal(right_hand, 0.0),\n",
        "            0.0,\n",
        "            (right_hand - RIGHT_HANDS_MEAN) / RIGHT_HANDS_STD,\n",
        "        )\n",
        "    right_hand = tf.reshape(right_hand, [-1, cfg.INPUT_SIZE, 21*2])\n",
        "    # POSE\n",
        "    pose = tf.slice(x, [0,0,82,0], [-1,cfg.INPUT_SIZE, 10, 2])\n",
        "    pose = tf.where(\n",
        "            tf.math.equal(pose, 0.0),\n",
        "            0.0,\n",
        "            (pose - POSE_MEAN) / POSE_STD,\n",
        "        )\n",
        "    pose = tf.reshape(pose, [-1, cfg.INPUT_SIZE, 10*2])\n",
        "    x = lips, left_hand, right_hand, pose\n",
        "    x = CustomEmbedding()(lips, left_hand, right_hand, pose, non_empty_frame_idxs)\n",
        "    # Encoder Transformer Blocks\n",
        "    x = Transformer(NUM_BLOCKS)(x, mask)\n",
        "    # Pooling\n",
        "    x = tf.reduce_sum(x * mask, axis=1) / tf.reduce_sum(mask, axis=1)\n",
        "    # Classification Layer\n",
        "    x = tf.keras.layers.Dense(cfg.NUM_CLASSES, activation=tf.keras.activations.softmax, kernel_initializer=INIT_GLOROT_UNIFORM)(x)\n",
        "    outputs = x\n",
        "    \n",
        "    # Create Tensorflow Model\n",
        "    model = tf.keras.models.Model(inputs=[frames, non_empty_frame_idxs], outputs=outputs)\n",
        "    \n",
        "    # Simple Categorical Crossentropy Loss\n",
        "    loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "    \n",
        "    # Adam Optimizer with weight decay\n",
        "    optimizer = tfa.optimizers.AdamW(learning_rate=1e-3, weight_decay=1e-5, clipnorm=1.0)\n",
        "    \n",
        "    lr_metric = get_lr_metric(optimizer)\n",
        "    metrics = [\"acc\",lr_metric]\n",
        "    model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "tf.keras.backend.clear_session()\n",
        "model_one = get_model()\n",
        "model_one.load_weights('D:/New folder/model_one.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "def lrfn(current_step, num_warmup_steps, lr_max, num_cycles=0.50, num_training_steps=cfg.N_EPOCHS):\n",
        "    \n",
        "    if current_step < num_warmup_steps:\n",
        "        if WARMUP_METHOD == 'log':\n",
        "            return lr_max * 0.10 ** (num_warmup_steps - current_step)\n",
        "        else:\n",
        "            return lr_max * 2 ** -(num_warmup_steps - current_step)\n",
        "    else:\n",
        "        progress = float(current_step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n",
        "\n",
        "        return max(0.0, 0.5 * (1.0 + math.cos(math.pi * float(num_cycles) * 2.0 * progress))) * lr_max"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 2000x1000 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def plot_lr_schedule(lr_schedule, epochs):\n",
        "    fig = plt.figure(figsize=(20, 10))\n",
        "    plt.plot([None] + lr_schedule + [None])\n",
        "    # X Labels\n",
        "    x = np.arange(1, epochs + 1)\n",
        "    x_axis_labels = [i if epochs <= 40 or i % 5 == 0 or i == 1 else None for i in range(1, epochs + 1)]\n",
        "    plt.xlim([1, epochs])\n",
        "    plt.xticks(x, x_axis_labels) # set tick step to 1 and let x axis start at 1\n",
        "    \n",
        "    # Increase y-limit for better readability\n",
        "    plt.ylim([0, max(lr_schedule) * 1.1])\n",
        "    \n",
        "    # Title\n",
        "    schedule_info = f'start: {lr_schedule[0]:.1E}, max: {max(lr_schedule):.1E}, final: {lr_schedule[-1]:.1E}'\n",
        "    plt.title(f'Step Learning Rate Schedule, {schedule_info}', size=18, pad=12)\n",
        "    \n",
        "    # Plot Learning Rates\n",
        "    for x, val in enumerate(lr_schedule):\n",
        "        if epochs <= 40 or x % 5 == 0 or x is epochs - 1:\n",
        "            if x < len(lr_schedule) - 1:\n",
        "                if lr_schedule[x - 1] < val:\n",
        "                    ha = 'right'\n",
        "                else:\n",
        "                    ha = 'left'\n",
        "            elif x == 0:\n",
        "                ha = 'right'\n",
        "            else:\n",
        "                ha = 'left'\n",
        "            plt.plot(x + 1, val, 'o', color='black');\n",
        "            offset_y = (max(lr_schedule) - min(lr_schedule)) * 0.02\n",
        "            plt.annotate(f'{val:.1E}', xy=(x + 1, val + offset_y), size=12, ha=ha)\n",
        "    \n",
        "    plt.xlabel('Epoch', size=16, labelpad=5)\n",
        "    plt.ylabel('Learning Rate', size=16, labelpad=5)\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "# Learning rate for encoder\n",
        "LR_SCHEDULE = [lrfn(step, num_warmup_steps=cfg.N_WARMUP_EPOCHS, lr_max=cfg.LR_MAX, num_cycles=0.50) for step in range(cfg.N_EPOCHS)]\n",
        "# Plot Learning Rate Schedule\n",
        "plot_lr_schedule(LR_SCHEDULE, epochs=cfg.N_EPOCHS)\n",
        "# Learning Rate Callback\n",
        "lr_callback = tf.keras.callbacks.LearningRateScheduler(lambda step: LR_SCHEDULE[step], verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Custom callback to update weight decay with learning rate\n",
        "class WeightDecayCallback(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, wd_ratio=cfg.WD_RATIO):\n",
        "        self.step_counter = 0\n",
        "        self.wd_ratio = wd_ratio\n",
        "    \n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "        model_one.optimizer.weight_decay = model_one.optimizer.learning_rate * self.wd_ratio\n",
        "        print(f'learning rate: {model_one.optimizer.learning_rate.numpy():.2e}, weight decay: {model_one.optimizer.weight_decay.numpy():.2e}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "25.4 ms ± 11.8 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit -n 100\n",
        "if cfg.TRAIN_MODEL:\n",
        "    # Verify model_one prediction is <<<100ms\n",
        "    model_one.predict_on_batch({ 'frames': X[:1], 'non_empty_frame_idxs': NON_EMPTY_FRAME_IDXS[:1] })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train = X[train_idxs]\n",
        "X_val = X[val_idxs]\n",
        "NON_EMPTY_FRAME_IDXS_TRAIN = NON_EMPTY_FRAME_IDXS[train_idxs]\n",
        "NON_EMPTY_FRAME_IDXS_VAL = NON_EMPTY_FRAME_IDXS[val_idxs]\n",
        "y_train = y[train_idxs]\n",
        "y_val = y[val_idxs]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "# delete variables as we go to free up RAM\n",
        "del X_train; del y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.001.\n",
            "learning rate: 1.00e-03, weight decay: 5.00e-05\n",
            "Epoch 1/100\n",
            "94/94 - 1026s - loss: 3.4567 - acc: 0.2598 - lr: 0.0010 - 1026s/epoch - 11s/step\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.0009997532801828658.\n",
            "learning rate: 1.00e-03, weight decay: 5.00e-05\n",
            "Epoch 2/100\n",
            "94/94 - 1004s - loss: 1.6325 - acc: 0.5897 - lr: 9.9975e-04 - 1004s/epoch - 11s/step\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.0009990133642141358.\n",
            "learning rate: 9.99e-04, weight decay: 5.00e-05\n",
            "Epoch 3/100\n",
            "94/94 - 996s - loss: 1.2195 - acc: 0.6881 - lr: 9.9901e-04 - 996s/epoch - 11s/step\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.00099778098230154.\n",
            "learning rate: 9.98e-04, weight decay: 4.99e-05\n",
            "Epoch 4/100\n",
            "94/94 - 956s - loss: 1.0116 - acc: 0.7375 - lr: 9.9778e-04 - 956s/epoch - 10s/step\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.000996057350657239.\n",
            "learning rate: 9.96e-04, weight decay: 4.98e-05\n",
            "Epoch 5/100\n",
            "94/94 - 1083s - loss: 0.8598 - acc: 0.7748 - lr: 9.9606e-04 - 1083s/epoch - 12s/step\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.0009938441702975688.\n",
            "learning rate: 9.94e-04, weight decay: 4.97e-05\n",
            "Epoch 6/100\n",
            "94/94 - 1061s - loss: 0.7629 - acc: 0.7979 - lr: 9.9384e-04 - 1061s/epoch - 11s/step\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.0009911436253643444.\n",
            "learning rate: 9.91e-04, weight decay: 4.96e-05\n",
            "Epoch 7/100\n",
            "94/94 - 1003s - loss: 0.6763 - acc: 0.8199 - lr: 9.9114e-04 - 1003s/epoch - 11s/step\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.0009879583809693738.\n",
            "learning rate: 9.88e-04, weight decay: 4.94e-05\n",
            "Epoch 8/100\n",
            "94/94 - 991s - loss: 0.6162 - acc: 0.8349 - lr: 9.8796e-04 - 991s/epoch - 11s/step\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.0009842915805643156.\n",
            "learning rate: 9.84e-04, weight decay: 4.92e-05\n",
            "Epoch 9/100\n",
            "94/94 - 960s - loss: 0.5636 - acc: 0.8466 - lr: 9.8429e-04 - 960s/epoch - 10s/step\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.0009801468428384716.\n",
            "learning rate: 9.80e-04, weight decay: 4.90e-05\n",
            "Epoch 10/100\n",
            "94/94 - 946s - loss: 0.5039 - acc: 0.8614 - lr: 9.8015e-04 - 946s/epoch - 10s/step\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 0.0009755282581475768.\n",
            "learning rate: 9.76e-04, weight decay: 4.88e-05\n",
            "Epoch 11/100\n",
            "94/94 - 942s - loss: 0.4662 - acc: 0.8710 - lr: 9.7553e-04 - 942s/epoch - 10s/step\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 0.0009704403844771128.\n",
            "learning rate: 9.70e-04, weight decay: 4.85e-05\n",
            "Epoch 12/100\n",
            "94/94 - 1026s - loss: 0.4222 - acc: 0.8819 - lr: 9.7044e-04 - 1026s/epoch - 11s/step\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 0.0009648882429441257.\n",
            "learning rate: 9.65e-04, weight decay: 4.82e-05\n",
            "Epoch 13/100\n",
            "94/94 - 966s - loss: 0.3840 - acc: 0.8925 - lr: 9.6489e-04 - 966s/epoch - 10s/step\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 0.0009588773128419905.\n",
            "learning rate: 9.59e-04, weight decay: 4.79e-05\n",
            "Epoch 14/100\n",
            "94/94 - 944s - loss: 0.3531 - acc: 0.8976 - lr: 9.5888e-04 - 944s/epoch - 10s/step\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 0.0009524135262330098.\n",
            "learning rate: 9.52e-04, weight decay: 4.76e-05\n",
            "Epoch 15/100\n",
            "94/94 - 950s - loss: 0.3362 - acc: 0.9038 - lr: 9.5241e-04 - 950s/epoch - 10s/step\n",
            "\n",
            "Epoch 16: LearningRateScheduler setting learning rate to 0.0009455032620941839.\n",
            "learning rate: 9.46e-04, weight decay: 4.73e-05\n",
            "Epoch 16/100\n",
            "94/94 - 946s - loss: 0.3108 - acc: 0.9097 - lr: 9.4550e-04 - 946s/epoch - 10s/step\n",
            "\n",
            "Epoch 17: LearningRateScheduler setting learning rate to 0.0009381533400219318.\n",
            "learning rate: 9.38e-04, weight decay: 4.69e-05\n",
            "Epoch 17/100\n",
            "94/94 - 948s - loss: 0.2756 - acc: 0.9199 - lr: 9.3815e-04 - 948s/epoch - 10s/step\n",
            "\n",
            "Epoch 18: LearningRateScheduler setting learning rate to 0.0009303710135019718.\n",
            "learning rate: 9.30e-04, weight decay: 4.65e-05\n",
            "Epoch 18/100\n",
            "94/94 - 950s - loss: 0.2635 - acc: 0.9223 - lr: 9.3037e-04 - 950s/epoch - 10s/step\n",
            "\n",
            "Epoch 19: LearningRateScheduler setting learning rate to 0.0009221639627510075.\n",
            "learning rate: 9.22e-04, weight decay: 4.61e-05\n",
            "Epoch 19/100\n",
            "94/94 - 952s - loss: 0.2470 - acc: 0.9269 - lr: 9.2216e-04 - 952s/epoch - 10s/step\n",
            "\n",
            "Epoch 20: LearningRateScheduler setting learning rate to 0.0009135402871372809.\n",
            "learning rate: 9.14e-04, weight decay: 4.57e-05\n",
            "Epoch 20/100\n",
            "94/94 - 957s - loss: 0.2270 - acc: 0.9326 - lr: 9.1354e-04 - 957s/epoch - 10s/step\n",
            "\n",
            "Epoch 21: LearningRateScheduler setting learning rate to 0.0009045084971874737.\n",
            "learning rate: 9.05e-04, weight decay: 4.52e-05\n",
            "Epoch 21/100\n",
            "94/94 - 966s - loss: 0.2095 - acc: 0.9369 - lr: 9.0451e-04 - 966s/epoch - 10s/step\n",
            "\n",
            "Epoch 22: LearningRateScheduler setting learning rate to 0.0008950775061878452.\n",
            "learning rate: 8.95e-04, weight decay: 4.48e-05\n",
            "Epoch 22/100\n",
            "94/94 - 935s - loss: 0.2053 - acc: 0.9381 - lr: 8.9508e-04 - 935s/epoch - 10s/step\n",
            "\n",
            "Epoch 23: LearningRateScheduler setting learning rate to 0.0008852566213878947.\n",
            "learning rate: 8.85e-04, weight decay: 4.43e-05\n",
            "Epoch 23/100\n",
            "94/94 - 931s - loss: 0.1870 - acc: 0.9432 - lr: 8.8526e-04 - 931s/epoch - 10s/step\n",
            "\n",
            "Epoch 24: LearningRateScheduler setting learning rate to 0.0008750555348152298.\n",
            "learning rate: 8.75e-04, weight decay: 4.38e-05\n",
            "Epoch 24/100\n",
            "94/94 - 888s - loss: 0.1811 - acc: 0.9452 - lr: 8.7506e-04 - 888s/epoch - 9s/step\n",
            "\n",
            "Epoch 25: LearningRateScheduler setting learning rate to 0.0008644843137107057.\n",
            "learning rate: 8.64e-04, weight decay: 4.32e-05\n",
            "Epoch 25/100\n",
            "94/94 - 937s - loss: 0.1657 - acc: 0.9492 - lr: 8.6448e-04 - 937s/epoch - 10s/step\n",
            "\n",
            "Epoch 26: LearningRateScheduler setting learning rate to 0.0008535533905932737.\n",
            "learning rate: 8.54e-04, weight decay: 4.27e-05\n",
            "Epoch 26/100\n",
            "94/94 - 942s - loss: 0.1509 - acc: 0.9538 - lr: 8.5355e-04 - 942s/epoch - 10s/step\n",
            "\n",
            "Epoch 27: LearningRateScheduler setting learning rate to 0.0008422735529643444.\n",
            "learning rate: 8.42e-04, weight decay: 4.21e-05\n",
            "Epoch 27/100\n",
            "94/94 - 946s - loss: 0.1345 - acc: 0.9583 - lr: 8.4227e-04 - 946s/epoch - 10s/step\n",
            "\n",
            "Epoch 28: LearningRateScheduler setting learning rate to 0.0008306559326618259.\n",
            "learning rate: 8.31e-04, weight decay: 4.15e-05\n",
            "Epoch 28/100\n",
            "94/94 - 990s - loss: 0.1281 - acc: 0.9598 - lr: 8.3066e-04 - 990s/epoch - 11s/step\n",
            "\n",
            "Epoch 29: LearningRateScheduler setting learning rate to 0.0008187119948743449.\n",
            "learning rate: 8.19e-04, weight decay: 4.09e-05\n",
            "Epoch 29/100\n",
            "94/94 - 1079s - loss: 0.1211 - acc: 0.9631 - lr: 8.1871e-04 - 1079s/epoch - 11s/step\n",
            "\n",
            "Epoch 30: LearningRateScheduler setting learning rate to 0.0008064535268264883.\n",
            "learning rate: 8.06e-04, weight decay: 4.03e-05\n",
            "Epoch 30/100\n",
            "94/94 - 1078s - loss: 0.1144 - acc: 0.9647 - lr: 8.0645e-04 - 1078s/epoch - 11s/step\n",
            "\n",
            "Epoch 31: LearningRateScheduler setting learning rate to 0.0007938926261462366.\n",
            "learning rate: 7.94e-04, weight decay: 3.97e-05\n",
            "Epoch 31/100\n",
            "94/94 - 958s - loss: 0.0968 - acc: 0.9704 - lr: 7.9389e-04 - 958s/epoch - 10s/step\n",
            "\n",
            "Epoch 32: LearningRateScheduler setting learning rate to 0.0007810416889260653.\n",
            "learning rate: 7.81e-04, weight decay: 3.91e-05\n",
            "Epoch 32/100\n",
            "94/94 - 871s - loss: 0.1035 - acc: 0.9677 - lr: 7.8104e-04 - 871s/epoch - 9s/step\n",
            "\n",
            "Epoch 33: LearningRateScheduler setting learning rate to 0.0007679133974894983.\n",
            "learning rate: 7.68e-04, weight decay: 3.84e-05\n",
            "Epoch 33/100\n",
            "94/94 - 946s - loss: 0.0925 - acc: 0.9708 - lr: 7.6791e-04 - 946s/epoch - 10s/step\n",
            "\n",
            "Epoch 34: LearningRateScheduler setting learning rate to 0.0007545207078751857.\n",
            "learning rate: 7.55e-04, weight decay: 3.77e-05\n",
            "Epoch 34/100\n",
            "94/94 - 995s - loss: 0.0799 - acc: 0.9761 - lr: 7.5452e-04 - 995s/epoch - 11s/step\n",
            "\n",
            "Epoch 35: LearningRateScheduler setting learning rate to 0.0007408768370508576.\n",
            "learning rate: 7.41e-04, weight decay: 3.70e-05\n",
            "Epoch 35/100\n",
            "94/94 - 985s - loss: 0.0752 - acc: 0.9772 - lr: 7.4088e-04 - 985s/epoch - 10s/step\n",
            "\n",
            "Epoch 36: LearningRateScheduler setting learning rate to 0.0007269952498697733.\n",
            "learning rate: 7.27e-04, weight decay: 3.63e-05\n",
            "Epoch 36/100\n",
            "94/94 - 978s - loss: 0.0758 - acc: 0.9765 - lr: 7.2700e-04 - 978s/epoch - 10s/step\n",
            "\n",
            "Epoch 37: LearningRateScheduler setting learning rate to 0.0007128896457825364.\n",
            "learning rate: 7.13e-04, weight decay: 3.56e-05\n",
            "Epoch 37/100\n",
            "94/94 - 982s - loss: 0.0756 - acc: 0.9769 - lr: 7.1289e-04 - 982s/epoch - 10s/step\n",
            "\n",
            "Epoch 38: LearningRateScheduler setting learning rate to 0.0006985739453173903.\n",
            "learning rate: 6.99e-04, weight decay: 3.49e-05\n",
            "Epoch 38/100\n",
            "94/94 - 986s - loss: 0.0682 - acc: 0.9785 - lr: 6.9857e-04 - 986s/epoch - 10s/step\n",
            "\n",
            "Epoch 39: LearningRateScheduler setting learning rate to 0.0006840622763423391.\n",
            "learning rate: 6.84e-04, weight decay: 3.42e-05\n",
            "Epoch 39/100\n",
            "94/94 - 989s - loss: 0.0598 - acc: 0.9821 - lr: 6.8406e-04 - 989s/epoch - 11s/step\n",
            "\n",
            "Epoch 40: LearningRateScheduler setting learning rate to 0.0006693689601226458.\n",
            "learning rate: 6.69e-04, weight decay: 3.35e-05\n",
            "Epoch 40/100\n",
            "94/94 - 992s - loss: 0.0605 - acc: 0.9812 - lr: 6.6937e-04 - 992s/epoch - 11s/step\n",
            "\n",
            "Epoch 41: LearningRateScheduler setting learning rate to 0.0006545084971874737.\n",
            "learning rate: 6.55e-04, weight decay: 3.27e-05\n",
            "Epoch 41/100\n",
            "94/94 - 993s - loss: 0.0483 - acc: 0.9851 - lr: 6.5451e-04 - 993s/epoch - 11s/step\n",
            "\n",
            "Epoch 42: LearningRateScheduler setting learning rate to 0.0006394955530196147.\n",
            "learning rate: 6.39e-04, weight decay: 3.20e-05\n",
            "Epoch 42/100\n",
            "94/94 - 1213s - loss: 0.0435 - acc: 0.9873 - lr: 6.3950e-04 - 1213s/epoch - 13s/step\n",
            "\n",
            "Epoch 43: LearningRateScheduler setting learning rate to 0.0006243449435824276.\n",
            "learning rate: 6.24e-04, weight decay: 3.12e-05\n",
            "Epoch 43/100\n",
            "94/94 - 1249s - loss: 0.0367 - acc: 0.9895 - lr: 6.2434e-04 - 1249s/epoch - 13s/step\n",
            "\n",
            "Epoch 44: LearningRateScheduler setting learning rate to 0.0006090716206982714.\n",
            "learning rate: 6.09e-04, weight decay: 3.05e-05\n",
            "Epoch 44/100\n",
            "94/94 - 1286s - loss: 0.0305 - acc: 0.9911 - lr: 6.0907e-04 - 1286s/epoch - 14s/step\n",
            "\n",
            "Epoch 45: LearningRateScheduler setting learning rate to 0.0005936906572928624.\n",
            "learning rate: 5.94e-04, weight decay: 2.97e-05\n",
            "Epoch 45/100\n",
            "94/94 - 1255s - loss: 0.0296 - acc: 0.9914 - lr: 5.9369e-04 - 1255s/epoch - 13s/step\n",
            "\n",
            "Epoch 46: LearningRateScheduler setting learning rate to 0.0005782172325201155.\n",
            "learning rate: 5.78e-04, weight decay: 2.89e-05\n",
            "Epoch 46/100\n",
            "94/94 - 1204s - loss: 0.0271 - acc: 0.9926 - lr: 5.7822e-04 - 1204s/epoch - 13s/step\n",
            "\n",
            "Epoch 47: LearningRateScheduler setting learning rate to 0.0005626666167821521.\n",
            "learning rate: 5.63e-04, weight decay: 2.81e-05\n",
            "Epoch 47/100\n",
            "94/94 - 1018s - loss: 0.0221 - acc: 0.9940 - lr: 5.6267e-04 - 1018s/epoch - 11s/step\n",
            "\n",
            "Epoch 48: LearningRateScheduler setting learning rate to 0.0005470541566592572.\n",
            "learning rate: 5.47e-04, weight decay: 2.74e-05\n",
            "Epoch 48/100\n",
            "94/94 - 969s - loss: 0.0225 - acc: 0.9939 - lr: 5.4705e-04 - 969s/epoch - 10s/step\n",
            "\n",
            "Epoch 49: LearningRateScheduler setting learning rate to 0.0005313952597646568.\n",
            "learning rate: 5.31e-04, weight decay: 2.66e-05\n",
            "Epoch 49/100\n",
            "94/94 - 942s - loss: 0.0187 - acc: 0.9951 - lr: 5.3140e-04 - 942s/epoch - 10s/step\n",
            "\n",
            "Epoch 50: LearningRateScheduler setting learning rate to 0.0005157053795390641.\n",
            "learning rate: 5.16e-04, weight decay: 2.58e-05\n",
            "Epoch 50/100\n",
            "94/94 - 946s - loss: 0.0157 - acc: 0.9960 - lr: 5.1571e-04 - 946s/epoch - 10s/step\n",
            "\n",
            "Epoch 51: LearningRateScheduler setting learning rate to 0.0005.\n",
            "learning rate: 5.00e-04, weight decay: 2.50e-05\n",
            "Epoch 51/100\n",
            "94/94 - 941s - loss: 0.0149 - acc: 0.9961 - lr: 5.0000e-04 - 941s/epoch - 10s/step\n",
            "\n",
            "Epoch 52: LearningRateScheduler setting learning rate to 0.00048429462046093585.\n",
            "learning rate: 4.84e-04, weight decay: 2.42e-05\n",
            "Epoch 52/100\n",
            "94/94 - 956s - loss: 0.0129 - acc: 0.9971 - lr: 4.8429e-04 - 956s/epoch - 10s/step\n",
            "\n",
            "Epoch 53: LearningRateScheduler setting learning rate to 0.0004686047402353433.\n",
            "learning rate: 4.69e-04, weight decay: 2.34e-05\n",
            "Epoch 53/100\n",
            "94/94 - 978s - loss: 0.0084 - acc: 0.9984 - lr: 4.6860e-04 - 978s/epoch - 10s/step\n",
            "\n",
            "Epoch 54: LearningRateScheduler setting learning rate to 0.00045294584334074284.\n",
            "learning rate: 4.53e-04, weight decay: 2.26e-05\n",
            "Epoch 54/100\n",
            "94/94 - 939s - loss: 0.0066 - acc: 0.9986 - lr: 4.5295e-04 - 939s/epoch - 10s/step\n",
            "\n",
            "Epoch 55: LearningRateScheduler setting learning rate to 0.00043733338321784784.\n",
            "learning rate: 4.37e-04, weight decay: 2.19e-05\n",
            "Epoch 55/100\n",
            "94/94 - 997s - loss: 0.0045 - acc: 0.9994 - lr: 4.3733e-04 - 997s/epoch - 11s/step\n",
            "\n",
            "Epoch 56: LearningRateScheduler setting learning rate to 0.0004217827674798845.\n",
            "learning rate: 4.22e-04, weight decay: 2.11e-05\n",
            "Epoch 56/100\n",
            "94/94 - 1038s - loss: 0.0045 - acc: 0.9993 - lr: 4.2178e-04 - 1038s/epoch - 11s/step\n",
            "\n",
            "Epoch 57: LearningRateScheduler setting learning rate to 0.0004063093427071376.\n",
            "learning rate: 4.06e-04, weight decay: 2.03e-05\n",
            "Epoch 57/100\n",
            "94/94 - 1667s - loss: 0.0040 - acc: 0.9994 - lr: 4.0631e-04 - 1667s/epoch - 18s/step\n",
            "\n",
            "Epoch 58: LearningRateScheduler setting learning rate to 0.0003909283793017289.\n",
            "learning rate: 3.91e-04, weight decay: 1.95e-05\n",
            "Epoch 58/100\n",
            "94/94 - 1878s - loss: 0.0028 - acc: 0.9996 - lr: 3.9093e-04 - 1878s/epoch - 20s/step\n",
            "\n",
            "Epoch 59: LearningRateScheduler setting learning rate to 0.0003756550564175727.\n",
            "learning rate: 3.76e-04, weight decay: 1.88e-05\n",
            "Epoch 59/100\n",
            "94/94 - 1009s - loss: 0.0027 - acc: 0.9997 - lr: 3.7566e-04 - 1009s/epoch - 11s/step\n",
            "\n",
            "Epoch 60: LearningRateScheduler setting learning rate to 0.0003605044469803854.\n",
            "learning rate: 3.61e-04, weight decay: 1.80e-05\n",
            "Epoch 60/100\n",
            "94/94 - 1012s - loss: 0.0018 - acc: 0.9998 - lr: 3.6050e-04 - 1012s/epoch - 11s/step\n",
            "\n",
            "Epoch 61: LearningRateScheduler setting learning rate to 0.00034549150281252633.\n",
            "learning rate: 3.45e-04, weight decay: 1.73e-05\n",
            "Epoch 61/100\n",
            "94/94 - 1048s - loss: 0.0021 - acc: 0.9997 - lr: 3.4549e-04 - 1048s/epoch - 11s/step\n",
            "\n",
            "Epoch 62: LearningRateScheduler setting learning rate to 0.0003306310398773543.\n",
            "learning rate: 3.31e-04, weight decay: 1.65e-05\n",
            "Epoch 62/100\n",
            "94/94 - 1043s - loss: 0.0017 - acc: 0.9998 - lr: 3.3063e-04 - 1043s/epoch - 11s/step\n",
            "\n",
            "Epoch 63: LearningRateScheduler setting learning rate to 0.00031593772365766105.\n",
            "learning rate: 3.16e-04, weight decay: 1.58e-05\n",
            "Epoch 63/100\n",
            "94/94 - 1039s - loss: 0.0020 - acc: 0.9998 - lr: 3.1594e-04 - 1039s/epoch - 11s/step\n",
            "\n",
            "Epoch 64: LearningRateScheduler setting learning rate to 0.00030142605468260977.\n",
            "learning rate: 3.01e-04, weight decay: 1.51e-05\n",
            "Epoch 64/100\n",
            "94/94 - 1044s - loss: 0.0015 - acc: 0.9999 - lr: 3.0143e-04 - 1044s/epoch - 11s/step\n",
            "\n",
            "Epoch 65: LearningRateScheduler setting learning rate to 0.00028711035421746366.\n",
            "learning rate: 2.87e-04, weight decay: 1.44e-05\n",
            "Epoch 65/100\n",
            "94/94 - 1043s - loss: 0.0013 - acc: 0.9999 - lr: 2.8711e-04 - 1043s/epoch - 11s/step\n",
            "\n",
            "Epoch 66: LearningRateScheduler setting learning rate to 0.00027300475013022663.\n",
            "learning rate: 2.73e-04, weight decay: 1.37e-05\n",
            "Epoch 66/100\n",
            "94/94 - 1045s - loss: 0.0012 - acc: 1.0000 - lr: 2.7300e-04 - 1045s/epoch - 11s/step\n",
            "\n",
            "Epoch 67: LearningRateScheduler setting learning rate to 0.0002591231629491423.\n",
            "learning rate: 2.59e-04, weight decay: 1.30e-05\n",
            "Epoch 67/100\n",
            "94/94 - 1043s - loss: 0.0012 - acc: 0.9999 - lr: 2.5912e-04 - 1043s/epoch - 11s/step\n",
            "\n",
            "Epoch 68: LearningRateScheduler setting learning rate to 0.00024547929212481435.\n",
            "learning rate: 2.45e-04, weight decay: 1.23e-05\n",
            "Epoch 68/100\n",
            "94/94 - 1067s - loss: 9.3133e-04 - acc: 1.0000 - lr: 2.4548e-04 - 1067s/epoch - 11s/step\n",
            "\n",
            "Epoch 69: LearningRateScheduler setting learning rate to 0.00023208660251050156.\n",
            "learning rate: 2.32e-04, weight decay: 1.16e-05\n",
            "Epoch 69/100\n",
            "94/94 - 1137s - loss: 0.0010 - acc: 0.9999 - lr: 2.3209e-04 - 1137s/epoch - 12s/step\n",
            "\n",
            "Epoch 70: LearningRateScheduler setting learning rate to 0.0002189583110739348.\n",
            "learning rate: 2.19e-04, weight decay: 1.09e-05\n",
            "Epoch 70/100\n",
            "94/94 - 1034s - loss: 0.0011 - acc: 0.9999 - lr: 2.1896e-04 - 1034s/epoch - 11s/step\n",
            "\n",
            "Epoch 71: LearningRateScheduler setting learning rate to 0.00020610737385376348.\n",
            "learning rate: 2.06e-04, weight decay: 1.03e-05\n",
            "Epoch 71/100\n",
            "94/94 - 1001s - loss: 9.8754e-04 - acc: 1.0000 - lr: 2.0611e-04 - 1001s/epoch - 11s/step\n",
            "\n",
            "Epoch 72: LearningRateScheduler setting learning rate to 0.00019354647317351188.\n",
            "learning rate: 1.94e-04, weight decay: 9.68e-06\n",
            "Epoch 72/100\n",
            "94/94 - 4029s - loss: 9.3576e-04 - acc: 1.0000 - lr: 1.9355e-04 - 4029s/epoch - 43s/step\n",
            "\n",
            "Epoch 73: LearningRateScheduler setting learning rate to 0.00018128800512565513.\n",
            "learning rate: 1.81e-04, weight decay: 9.06e-06\n",
            "Epoch 73/100\n",
            "94/94 - 2879s - loss: 8.7353e-04 - acc: 0.9999 - lr: 1.8129e-04 - 2879s/epoch - 31s/step\n",
            "\n",
            "Epoch 74: LearningRateScheduler setting learning rate to 0.00016934406733817414.\n",
            "learning rate: 1.69e-04, weight decay: 8.47e-06\n",
            "Epoch 74/100\n",
            "94/94 - 906s - loss: 7.4283e-04 - acc: 1.0000 - lr: 1.6934e-04 - 906s/epoch - 10s/step\n",
            "\n",
            "Epoch 75: LearningRateScheduler setting learning rate to 0.00015772644703565563.\n",
            "learning rate: 1.58e-04, weight decay: 7.89e-06\n",
            "Epoch 75/100\n",
            "94/94 - 872s - loss: 7.1970e-04 - acc: 1.0000 - lr: 1.5773e-04 - 872s/epoch - 9s/step\n",
            "\n",
            "Epoch 76: LearningRateScheduler setting learning rate to 0.00014644660940672628.\n",
            "learning rate: 1.46e-04, weight decay: 7.32e-06\n",
            "Epoch 76/100\n",
            "94/94 - 874s - loss: 7.2387e-04 - acc: 1.0000 - lr: 1.4645e-04 - 874s/epoch - 9s/step\n",
            "\n",
            "Epoch 77: LearningRateScheduler setting learning rate to 0.00013551568628929433.\n",
            "learning rate: 1.36e-04, weight decay: 6.78e-06\n",
            "Epoch 77/100\n",
            "94/94 - 877s - loss: 6.8972e-04 - acc: 1.0000 - lr: 1.3552e-04 - 877s/epoch - 9s/step\n",
            "\n",
            "Epoch 78: LearningRateScheduler setting learning rate to 0.00012494446518477025.\n",
            "learning rate: 1.25e-04, weight decay: 6.25e-06\n",
            "Epoch 78/100\n",
            "94/94 - 878s - loss: 6.6670e-04 - acc: 1.0000 - lr: 1.2494e-04 - 878s/epoch - 9s/step\n",
            "\n",
            "Epoch 79: LearningRateScheduler setting learning rate to 0.00011474337861210544.\n",
            "learning rate: 1.15e-04, weight decay: 5.74e-06\n",
            "Epoch 79/100\n",
            "94/94 - 874s - loss: 6.6799e-04 - acc: 1.0000 - lr: 1.1474e-04 - 874s/epoch - 9s/step\n",
            "\n",
            "Epoch 80: LearningRateScheduler setting learning rate to 0.00010492249381215479.\n",
            "learning rate: 1.05e-04, weight decay: 5.25e-06\n",
            "Epoch 80/100\n",
            "94/94 - 917s - loss: 5.5969e-04 - acc: 1.0000 - lr: 1.0492e-04 - 917s/epoch - 10s/step\n",
            "\n",
            "Epoch 81: LearningRateScheduler setting learning rate to 9.549150281252633e-05.\n",
            "learning rate: 9.55e-05, weight decay: 4.77e-06\n",
            "Epoch 81/100\n",
            "94/94 - 942s - loss: 5.9177e-04 - acc: 1.0000 - lr: 9.5492e-05 - 942s/epoch - 10s/step\n",
            "\n",
            "Epoch 82: LearningRateScheduler setting learning rate to 8.645971286271903e-05.\n",
            "learning rate: 8.65e-05, weight decay: 4.32e-06\n",
            "Epoch 82/100\n",
            "94/94 - 941s - loss: 5.6155e-04 - acc: 1.0000 - lr: 8.6460e-05 - 941s/epoch - 10s/step\n",
            "\n",
            "Epoch 83: LearningRateScheduler setting learning rate to 7.783603724899258e-05.\n",
            "learning rate: 7.78e-05, weight decay: 3.89e-06\n",
            "Epoch 83/100\n",
            "94/94 - 936s - loss: 5.3310e-04 - acc: 1.0000 - lr: 7.7836e-05 - 936s/epoch - 10s/step\n",
            "\n",
            "Epoch 84: LearningRateScheduler setting learning rate to 6.962898649802824e-05.\n",
            "learning rate: 6.96e-05, weight decay: 3.48e-06\n",
            "Epoch 84/100\n",
            "94/94 - 940s - loss: 5.5576e-04 - acc: 1.0000 - lr: 6.9629e-05 - 940s/epoch - 10s/step\n",
            "\n",
            "Epoch 85: LearningRateScheduler setting learning rate to 6.184665997806827e-05.\n",
            "learning rate: 6.18e-05, weight decay: 3.09e-06\n",
            "Epoch 85/100\n",
            "94/94 - 944s - loss: 5.2406e-04 - acc: 1.0000 - lr: 6.1847e-05 - 944s/epoch - 10s/step\n",
            "\n",
            "Epoch 86: LearningRateScheduler setting learning rate to 5.449673790581611e-05.\n",
            "learning rate: 5.45e-05, weight decay: 2.72e-06\n",
            "Epoch 86/100\n",
            "94/94 - 938s - loss: 5.1409e-04 - acc: 1.0000 - lr: 5.4497e-05 - 938s/epoch - 10s/step\n",
            "\n",
            "Epoch 87: LearningRateScheduler setting learning rate to 4.758647376699032e-05.\n",
            "learning rate: 4.76e-05, weight decay: 2.38e-06\n",
            "Epoch 87/100\n",
            "94/94 - 934s - loss: 5.1500e-04 - acc: 1.0000 - lr: 4.7586e-05 - 934s/epoch - 10s/step\n",
            "\n",
            "Epoch 88: LearningRateScheduler setting learning rate to 4.112268715800943e-05.\n",
            "learning rate: 4.11e-05, weight decay: 2.06e-06\n",
            "Epoch 88/100\n",
            "94/94 - 1023s - loss: 4.8440e-04 - acc: 1.0000 - lr: 4.1123e-05 - 1023s/epoch - 11s/step\n",
            "\n",
            "Epoch 89: LearningRateScheduler setting learning rate to 3.5111757055874326e-05.\n",
            "learning rate: 3.51e-05, weight decay: 1.76e-06\n",
            "Epoch 89/100\n",
            "94/94 - 971s - loss: 4.8013e-04 - acc: 1.0000 - lr: 3.5112e-05 - 971s/epoch - 10s/step\n",
            "\n",
            "Epoch 90: LearningRateScheduler setting learning rate to 2.9559615522887274e-05.\n",
            "learning rate: 2.96e-05, weight decay: 1.48e-06\n",
            "Epoch 90/100\n",
            "94/94 - 943s - loss: 4.9462e-04 - acc: 1.0000 - lr: 2.9560e-05 - 943s/epoch - 10s/step\n",
            "\n",
            "Epoch 91: LearningRateScheduler setting learning rate to 2.4471741852423235e-05.\n",
            "learning rate: 2.45e-05, weight decay: 1.22e-06\n",
            "Epoch 91/100\n",
            "94/94 - 950s - loss: 5.0046e-04 - acc: 1.0000 - lr: 2.4472e-05 - 950s/epoch - 10s/step\n",
            "\n",
            "Epoch 92: LearningRateScheduler setting learning rate to 1.985315716152847e-05.\n",
            "learning rate: 1.99e-05, weight decay: 9.93e-07\n",
            "Epoch 92/100\n",
            "94/94 - 951s - loss: 4.7421e-04 - acc: 1.0000 - lr: 1.9853e-05 - 951s/epoch - 10s/step\n",
            "\n",
            "Epoch 93: LearningRateScheduler setting learning rate to 1.5708419435684463e-05.\n",
            "learning rate: 1.57e-05, weight decay: 7.85e-07\n",
            "Epoch 93/100\n",
            "94/94 - 913s - loss: 4.7073e-04 - acc: 1.0000 - lr: 1.5708e-05 - 913s/epoch - 10s/step\n",
            "\n",
            "Epoch 94: LearningRateScheduler setting learning rate to 1.2041619030626282e-05.\n",
            "learning rate: 1.20e-05, weight decay: 6.02e-07\n",
            "Epoch 94/100\n",
            "94/94 - 861s - loss: 4.6411e-04 - acc: 1.0000 - lr: 1.2042e-05 - 861s/epoch - 9s/step\n",
            "\n",
            "Epoch 95: LearningRateScheduler setting learning rate to 8.856374635655695e-06.\n",
            "learning rate: 8.86e-06, weight decay: 4.43e-07\n",
            "Epoch 95/100\n",
            "94/94 - 848s - loss: 4.5926e-04 - acc: 1.0000 - lr: 8.8564e-06 - 848s/epoch - 9s/step\n",
            "\n",
            "Epoch 96: LearningRateScheduler setting learning rate to 6.15582970243117e-06.\n",
            "learning rate: 6.16e-06, weight decay: 3.08e-07\n",
            "Epoch 96/100\n",
            "94/94 - 894s - loss: 4.8754e-04 - acc: 1.0000 - lr: 6.1558e-06 - 894s/epoch - 10s/step\n",
            "\n",
            "Epoch 97: LearningRateScheduler setting learning rate to 3.942649342761117e-06.\n",
            "learning rate: 3.94e-06, weight decay: 1.97e-07\n",
            "Epoch 97/100\n",
            "94/94 - 954s - loss: 4.8394e-04 - acc: 1.0000 - lr: 3.9426e-06 - 954s/epoch - 10s/step\n",
            "\n",
            "Epoch 98: LearningRateScheduler setting learning rate to 2.219017698460002e-06.\n",
            "learning rate: 2.22e-06, weight decay: 1.11e-07\n",
            "Epoch 98/100\n",
            "94/94 - 947s - loss: 4.6803e-04 - acc: 1.0000 - lr: 2.2190e-06 - 947s/epoch - 10s/step\n",
            "\n",
            "Epoch 99: LearningRateScheduler setting learning rate to 9.866357858642206e-07.\n",
            "learning rate: 9.87e-07, weight decay: 4.93e-08\n",
            "Epoch 99/100\n",
            "94/94 - 950s - loss: 4.7019e-04 - acc: 1.0000 - lr: 9.8664e-07 - 950s/epoch - 10s/step\n",
            "\n",
            "Epoch 100: LearningRateScheduler setting learning rate to 2.467198171342e-07.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 100/100\n",
            "94/94 - 952s - loss: 4.6798e-04 - acc: 1.0000 - lr: 2.4672e-07 - 952s/epoch - 10s/step\n"
          ]
        }
      ],
      "source": [
        "if cfg.TRAIN_MODEL:\n",
        "    tf.keras.backend.clear_session()\n",
        "    callbacks=[\n",
        "            lr_callback,\n",
        "            WeightDecayCallback(),\n",
        "           # wandb.keras.WandbCallback()\n",
        "    ]\n",
        "    model_one.fit(\n",
        "        x=get_train_batch_all_signs(X, y, NON_EMPTY_FRAME_IDXS),\n",
        "        steps_per_epoch=len(X) // (cfg.NUM_CLASSES * cfg.BATCH_ALL_SIGNS_N),\n",
        "        epochs=cfg.N_EPOCHS,\n",
        "        batch_size=cfg.BATCH_SIZE,\n",
        "        callbacks=callbacks,\n",
        "        verbose = 2,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "# save model artifacts\n",
        "if cfg.TRAIN_MODEL:# serialize weights to HDF5\n",
        "    model_one.save_weights(\"model_one.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "399/399 - 62s - 62s/epoch - 155ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_val_pred = model_one.predict({ 'frames': X_val, 'non_empty_frame_idxs': NON_EMPTY_FRAME_IDXS_VAL }, verbose=2).argmax(axis=1)\n",
        "np.mean(y_val == y_val_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "def read_parquet(path): \n",
        "    return pd.read_parquet(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "label_map = json.load(open(LABEL_MAP_PATH, 'r'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "LIPS_START = 0\n",
        "LEFT_HAND_START = LIPS_IDXS.size\n",
        "RIGHT_HAND_START = LEFT_HAND_START + LEFT_HAND_IDXS.size\n",
        "POSE_START = RIGHT_HAND_START + RIGHT_HAND_IDXS.size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((15, 168), 84, 3864)"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "LEFT_HAND_OFFSET = 468\n",
        "POSE_OFFSET = LEFT_HAND_OFFSET+21\n",
        "RIGHT_HAND_OFFSET = POSE_OFFSET+33\n",
        "## average over the entire face\n",
        "\n",
        "lip_landmarks = [61, 185, 40, 39, 37,  0, 267, 269, 270, 409,\n",
        "                 291,146, 91,181, 84, 17, 314, 405, 321, 375, \n",
        "                 78, 191, 80, 81, 82, 13, 312, 311, 310, 415, \n",
        "                 95, 88, 178, 87, 14,317, 402, 318, 324, 308]\n",
        "left_hand_landmarks = list(range(LEFT_HAND_OFFSET, LEFT_HAND_OFFSET+21))\n",
        "right_hand_landmarks = list(range(RIGHT_HAND_OFFSET, RIGHT_HAND_OFFSET+21))\n",
        "pose_landmarks = list(range(POSE_OFFSET, POSE_OFFSET+33))\n",
        "\n",
        "cfg.SEGMENTS=3\n",
        "cfg.NUM_FRAMES=15\n",
        "cfg.DROP_Z=True\n",
        "cfg.averaging_sets=[\n",
        "        [0, 468],\n",
        "        [POSE_OFFSET, 33],\n",
        "    ]\n",
        "cfg.average_over_pose=True\n",
        "\n",
        "\n",
        "point_landmarks = lip_landmarks + left_hand_landmarks+ right_hand_landmarks\n",
        "if not cfg.average_over_pose: \n",
        "    point_landmarks = point_landmarks + pose_landmarks\n",
        "\n",
        "\n",
        "TOT_LANDMARKS = len(point_landmarks) + len(cfg.averaging_sets)\n",
        "if cfg.DROP_Z:\n",
        "    INPUT_SHAPE = (cfg.NUM_FRAMES,TOT_LANDMARKS*2)\n",
        "else:\n",
        "    INPUT_SHAPE = (cfg.NUM_FRAMES,TOT_LANDMARKS*3)\n",
        "    \n",
        "FLAT_INPUT_SHAPE = (INPUT_SHAPE[0] + 2 * (cfg.SEGMENTS + 1)) * INPUT_SHAPE[1]\n",
        "\n",
        "INPUT_SHAPE, TOT_LANDMARKS, FLAT_INPUT_SHAPE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "def tf_nan_mean(x, axis=0):\n",
        "    return tf.reduce_sum(tf.where(tf.math.is_nan(x), tf.zeros_like(x), x), axis=axis) / tf.reduce_sum(tf.where(tf.math.is_nan(x), tf.zeros_like(x), tf.ones_like(x)), axis=axis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "def tf_nan_std(x, axis=0):\n",
        "    d = x - tf_nan_mean(x, axis=axis)\n",
        "    return tf.math.sqrt(tf_nan_mean(d * d, axis=axis))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "def flatten_means_and_stds(x, axis=0):\n",
        "    # Get means and stds\n",
        "    x_mean = tf_nan_mean(x, axis=0)\n",
        "    x_std  = tf_nan_std(x,  axis=0)\n",
        "\n",
        "    x_out = tf.concat([x_mean, x_std], axis=0)\n",
        "    x_out = tf.reshape(x_out, (1, INPUT_SHAPE[1]*2))\n",
        "    x_out = tf.where(tf.math.is_finite(x_out), x_out, tf.zeros_like(x_out))\n",
        "    return x_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "class  FeatureGen_1(tf.keras.layers.Layer):\n",
        "    def __init__(self):\n",
        "        super(FeatureGen_1, self).__init__()\n",
        "    def call(self, x_in):\n",
        "        if not isinstance(x_in, (np.ndarray, tf.Tensor)): \n",
        "            x_in = load_relevant_data_subset(x_in)\n",
        "        if cfg.DROP_Z:\n",
        "            x_in = x_in[:, :, 0:2]\n",
        "        x_list = [tf.expand_dims(tf_nan_mean(x_in[:, av_set[0]:av_set[0]+av_set[1], :], axis=1), axis=1) for av_set in cfg.averaging_sets]\n",
        "        x_list.append(tf.gather(x_in, point_landmarks, axis=1))\n",
        "        x = tf.concat(x_list, 1)\n",
        "\n",
        "        x_padded = x\n",
        "\n",
        "        for i in range(cfg.SEGMENTS):\n",
        "            # once right pad, once left\n",
        "            p0 = tf.where( ((tf.shape(x_padded)[0] % cfg.SEGMENTS) > 0) & ((i % 2) != 0) , 1, 0)\n",
        "            p1 = tf.where( ((tf.shape(x_padded)[0] % cfg.SEGMENTS) > 0) & ((i % 2) == 0) , 1, 0)\n",
        "            paddings = [[p0, p1], [0, 0], [0, 0]]\n",
        "            x_padded = tf.pad(x_padded, paddings, mode=\"SYMMETRIC\")\n",
        "        x_list = tf.split(x_padded, cfg.SEGMENTS)\n",
        "        x_list = [flatten_means_and_stds(_x, axis=0) for _x in x_list]\n",
        "\n",
        "        x_list.append(flatten_means_and_stds(x, axis=0))\n",
        "\n",
        "        ## Resize only dimension 0. Resize can't handle nan, so replace nan with that dimension's avg value to reduce impact.\n",
        "        x = tf.image.resize(\n",
        "            tf.where(tf.math.is_finite(x), x, tf_nan_mean(x, axis=0)), \n",
        "            [cfg.NUM_FRAMES, TOT_LANDMARKS])\n",
        "        x = tf.reshape(x, (1, INPUT_SHAPE[0]*INPUT_SHAPE[1]))\n",
        "        x = tf.where(tf.math.is_nan(x), tf.zeros_like(x), x)\n",
        "        x_list.append(x)\n",
        "        x = tf.concat(x_list, axis=1)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TensorShape([1, 3864])"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "feature_gen1 = FeatureGen_1()\n",
        "feature_gen1(load_relevant_data_subset(DATA_DIR/train.path[0])).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_PATH = DATA_DIR/'asl-features/feature_data.npy'\n",
        "Y_PATH = DATA_DIR/'asl-features/feature_labels.npy'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: total: 1.97 s\n",
            "Wall time: 16.2 s\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "((94477, 3864), (94477,))"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%%time\n",
        "X = np.load(X_PATH)\n",
        "y = np.load(Y_PATH)\n",
        "X.shape, y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(94477, 4)"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df = pd.read_csv(TRAIN_CSV_PATH)\n",
        "label_map = json.load(open(LABEL_MAP_PATH, 'r'))\n",
        "# train_df['label'] = train_df.sign.map(label_map\n",
        "train_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>participant_id</th>\n",
              "      <th>sequence_id</th>\n",
              "      <th>sign</th>\n",
              "      <th>fold</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>train_landmark_files/26734/1000035562.parquet</td>\n",
              "      <td>26734</td>\n",
              "      <td>1000035562</td>\n",
              "      <td>blow</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>train_landmark_files/28656/1000106739.parquet</td>\n",
              "      <td>28656</td>\n",
              "      <td>1000106739</td>\n",
              "      <td>wait</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>train_landmark_files/16069/100015657.parquet</td>\n",
              "      <td>16069</td>\n",
              "      <td>100015657</td>\n",
              "      <td>cloud</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>train_landmark_files/25571/1000210073.parquet</td>\n",
              "      <td>25571</td>\n",
              "      <td>1000210073</td>\n",
              "      <td>bird</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>train_landmark_files/62590/1000240708.parquet</td>\n",
              "      <td>62590</td>\n",
              "      <td>1000240708</td>\n",
              "      <td>owie</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            path  participant_id  sequence_id  \\\n",
              "0  train_landmark_files/26734/1000035562.parquet           26734   1000035562   \n",
              "1  train_landmark_files/28656/1000106739.parquet           28656   1000106739   \n",
              "2   train_landmark_files/16069/100015657.parquet           16069    100015657   \n",
              "3  train_landmark_files/25571/1000210073.parquet           25571   1000210073   \n",
              "4  train_landmark_files/62590/1000240708.parquet           62590   1000240708   \n",
              "\n",
              "    sign  fold  \n",
              "0   blow     0  \n",
              "1   wait     3  \n",
              "2  cloud     6  \n",
              "3   bird     3  \n",
              "4   owie     8  "
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "N_PARTICIPANTS = train_df.participant_id.nunique()\n",
        "sgkf = StratifiedGroupKFold(n_splits=10, shuffle=True, random_state=43)\n",
        "train_df['fold'] = -1\n",
        "for i, (train_idx, val_idx) in enumerate(sgkf.split(train_df.index, train_df.sign, train_df.participant_id)):\n",
        "    train_df.loc[val_idx, 'fold'] = i\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_idxs = train_df.query(\"fold!=0\").index.values\n",
        "val_idxs = train_df.query(\"fold==0\").index.values\n",
        "\n",
        "x_train, y_train = X[train_idxs], y[train_idxs]\n",
        "x_test, y_test = X[val_idxs], y[val_idxs]\n",
        "\n",
        "n_classes = train_df.sign.nunique() #250"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [],
      "source": [
        "cfg.BLOCK_SIZES = [2048, 1024, 512]\n",
        "cfg.FLAT_FRAME_SHAPE = x_train.shape[1]\n",
        "cfg.DROPOUTS = [0.3, 0.1, 0.1]\n",
        "cfg.LEARNING_RATE = 1e-3\n",
        "cfg.training_data_path = (X_PATH, Y_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [],
      "source": [
        "cfg.EPOCHS = 100\n",
        "cfg.BATCH_SIZE = 256\n",
        "\n",
        "decay_steps = ((len(x_train)//cfg.BATCH_SIZE)*cfg.EPOCHS)\n",
        "\n",
        "cosine_decay_scheduler = tf.keras.optimizers.schedules.CosineDecay(\n",
        "    initial_learning_rate = cfg.LEARNING_RATE,\n",
        "    decay_steps = decay_steps,\n",
        "    alpha=0.001\n",
        ")\n",
        "optimizer = tf.keras.optimizers.Adam(cosine_decay_scheduler)\n",
        "\n",
        "\n",
        "def get_lr_metric(optimizer):\n",
        "    def lr(y_true, y_pred):\n",
        "        return optimizer.lr\n",
        "    return lr\n",
        "\n",
        "\n",
        "def fc_block(inputs, output_channels, dropout=0.2):\n",
        "    x = tf.keras.layers.Dense(output_channels)(inputs)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.Activation(\"gelu\")(x)\n",
        "    x = tf.keras.layers.Dropout(dropout)(x)\n",
        "    return x\n",
        "\n",
        "def get_model(n_labels=250, flat_frame_len=cfg.FLAT_FRAME_SHAPE):\n",
        "    _inputs = tf.keras.layers.Input(shape=(flat_frame_len,))\n",
        "    x = _inputs\n",
        "    \n",
        "    # Define layers\n",
        "    for i in range(len(cfg.DROPOUTS)):\n",
        "        x = fc_block(\n",
        "            x, output_channels=cfg.BLOCK_SIZES[i], \n",
        "            dropout=cfg.DROPOUTS[i]\n",
        "        )\n",
        "    \n",
        "    # Define output layer\n",
        "    _outputs = tf.keras.layers.Dense(n_labels, activation=\"softmax\")(x)\n",
        "    \n",
        "    # Build the model\n",
        "    model = tf.keras.models.Model(inputs=_inputs, outputs=_outputs)\n",
        "    return model\n",
        "\n",
        "lr_metric = get_lr_metric(optimizer)\n",
        "model_two = get_model()\n",
        "model_two.compile(optimizer, \"sparse_categorical_crossentropy\", \n",
        "              metrics=[\"acc\", lr_metric])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 3864)]            0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2048)              7915520   \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 2048)             8192      \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " activation (Activation)     (None, 2048)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1024)              2098176   \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 1024)             4096      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 1024)              0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 512)               524800    \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 512)              2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 512)               0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 250)               128250    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10,681,082\n",
            "Trainable params: 10,673,914\n",
            "Non-trainable params: 7,168\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "tf.keras.backend.clear_session()\n",
        "model_two.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [],
      "source": [
        "del x_train; del y_train; "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.001.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 1/100\n",
            "370/370 [==============================] - 93s 233ms/step - loss: 4.4528 - acc: 0.0768 - lr: 9.9970e-04\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.0009997532801828658.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 2/100\n",
            "370/370 [==============================] - 78s 211ms/step - loss: 3.2713 - acc: 0.2299 - lr: 9.9879e-04\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.0009990133642141358.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 3/100\n",
            "370/370 [==============================] - 78s 211ms/step - loss: 2.7692 - acc: 0.3293 - lr: 9.9727e-04\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.00099778098230154.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 4/100\n",
            "370/370 [==============================] - 77s 207ms/step - loss: 2.4798 - acc: 0.3891 - lr: 9.9515e-04\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.000996057350657239.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 5/100\n",
            "370/370 [==============================] - 75s 203ms/step - loss: 2.2727 - acc: 0.4339 - lr: 9.9242e-04\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.0009938441702975688.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 6/100\n",
            "370/370 [==============================] - 75s 201ms/step - loss: 2.1059 - acc: 0.4698 - lr: 9.8909e-04\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.0009911436253643444.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 7/100\n",
            "370/370 [==============================] - 74s 201ms/step - loss: 1.9804 - acc: 0.4978 - lr: 9.8517e-04\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.0009879583809693738.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 8/100\n",
            "370/370 [==============================] - 74s 201ms/step - loss: 1.8449 - acc: 0.5282 - lr: 9.8066e-04\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.0009842915805643156.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 9/100\n",
            "370/370 [==============================] - 77s 207ms/step - loss: 1.7853 - acc: 0.5413 - lr: 9.7557e-04\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.0009801468428384716.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 10/100\n",
            "370/370 [==============================] - 76s 204ms/step - loss: 1.6819 - acc: 0.5651 - lr: 9.6989e-04\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 0.0009755282581475768.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 11/100\n",
            "370/370 [==============================] - 75s 203ms/step - loss: 1.5831 - acc: 0.5871 - lr: 9.6365e-04\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 0.0009704403844771128.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 12/100\n",
            "370/370 [==============================] - 76s 206ms/step - loss: 1.5118 - acc: 0.6029 - lr: 9.5684e-04\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 0.0009648882429441257.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 13/100\n",
            "370/370 [==============================] - 75s 202ms/step - loss: 1.4565 - acc: 0.6160 - lr: 9.4947e-04\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 0.0009588773128419905.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 14/100\n",
            "370/370 [==============================] - 82s 223ms/step - loss: 1.3975 - acc: 0.6288 - lr: 9.4155e-04\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 0.0009524135262330098.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 15/100\n",
            "370/370 [==============================] - 87s 234ms/step - loss: 1.3418 - acc: 0.6414 - lr: 9.3310e-04\n",
            "\n",
            "Epoch 16: LearningRateScheduler setting learning rate to 0.0009455032620941839.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 16/100\n",
            "370/370 [==============================] - 81s 220ms/step - loss: 1.2754 - acc: 0.6581 - lr: 9.2413e-04\n",
            "\n",
            "Epoch 17: LearningRateScheduler setting learning rate to 0.0009381533400219318.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 17/100\n",
            "370/370 [==============================] - 89s 240ms/step - loss: 1.2355 - acc: 0.6669 - lr: 9.1463e-04\n",
            "\n",
            "Epoch 18: LearningRateScheduler setting learning rate to 0.0009303710135019718.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 18/100\n",
            "370/370 [==============================] - 93s 251ms/step - loss: 1.1952 - acc: 0.6743 - lr: 9.0463e-04\n",
            "\n",
            "Epoch 19: LearningRateScheduler setting learning rate to 0.0009221639627510075.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 19/100\n",
            "370/370 [==============================] - 85s 230ms/step - loss: 1.1389 - acc: 0.6893 - lr: 8.9414e-04\n",
            "\n",
            "Epoch 20: LearningRateScheduler setting learning rate to 0.0009135402871372809.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 20/100\n",
            "370/370 [==============================] - 84s 228ms/step - loss: 1.0973 - acc: 0.6992 - lr: 8.8317e-04\n",
            "\n",
            "Epoch 21: LearningRateScheduler setting learning rate to 0.0009045084971874737.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 21/100\n",
            "370/370 [==============================] - 85s 229ms/step - loss: 1.0594 - acc: 0.7069 - lr: 8.7173e-04\n",
            "\n",
            "Epoch 22: LearningRateScheduler setting learning rate to 0.0008950775061878452.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 22/100\n",
            "370/370 [==============================] - 86s 232ms/step - loss: 1.0216 - acc: 0.7143 - lr: 8.5984e-04\n",
            "\n",
            "Epoch 23: LearningRateScheduler setting learning rate to 0.0008852566213878947.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 23/100\n",
            "370/370 [==============================] - 81s 219ms/step - loss: 0.9897 - acc: 0.7232 - lr: 8.4752e-04\n",
            "\n",
            "Epoch 24: LearningRateScheduler setting learning rate to 0.0008750555348152298.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 24/100\n",
            "370/370 [==============================] - 80s 217ms/step - loss: 0.9422 - acc: 0.7344 - lr: 8.3477e-04\n",
            "\n",
            "Epoch 25: LearningRateScheduler setting learning rate to 0.0008644843137107057.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 25/100\n",
            "370/370 [==============================] - 80s 215ms/step - loss: 0.9136 - acc: 0.7399 - lr: 8.2161e-04\n",
            "\n",
            "Epoch 26: LearningRateScheduler setting learning rate to 0.0008535533905932737.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 26/100\n",
            "370/370 [==============================] - 79s 214ms/step - loss: 0.8710 - acc: 0.7521 - lr: 8.0806e-04\n",
            "\n",
            "Epoch 27: LearningRateScheduler setting learning rate to 0.0008422735529643444.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 27/100\n",
            "370/370 [==============================] - 81s 218ms/step - loss: 0.8597 - acc: 0.7542 - lr: 7.9414e-04\n",
            "\n",
            "Epoch 28: LearningRateScheduler setting learning rate to 0.0008306559326618259.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 28/100\n",
            "370/370 [==============================] - 74s 200ms/step - loss: 0.8378 - acc: 0.7593 - lr: 7.7986e-04\n",
            "\n",
            "Epoch 29: LearningRateScheduler setting learning rate to 0.0008187119948743449.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 29/100\n",
            "370/370 [==============================] - 75s 204ms/step - loss: 0.7890 - acc: 0.7720 - lr: 7.6523e-04\n",
            "\n",
            "Epoch 30: LearningRateScheduler setting learning rate to 0.0008064535268264883.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 30/100\n",
            "370/370 [==============================] - 74s 199ms/step - loss: 0.7525 - acc: 0.7803 - lr: 7.5029e-04\n",
            "\n",
            "Epoch 31: LearningRateScheduler setting learning rate to 0.0007938926261462366.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 31/100\n",
            "370/370 [==============================] - 76s 204ms/step - loss: 0.7246 - acc: 0.7874 - lr: 7.3504e-04\n",
            "\n",
            "Epoch 32: LearningRateScheduler setting learning rate to 0.0007810416889260653.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 32/100\n",
            "370/370 [==============================] - 76s 205ms/step - loss: 0.7050 - acc: 0.7936 - lr: 7.1951e-04\n",
            "\n",
            "Epoch 33: LearningRateScheduler setting learning rate to 0.0007679133974894983.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 33/100\n",
            "370/370 [==============================] - 75s 203ms/step - loss: 0.6777 - acc: 0.7992 - lr: 7.0371e-04\n",
            "\n",
            "Epoch 34: LearningRateScheduler setting learning rate to 0.0007545207078751857.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 34/100\n",
            "370/370 [==============================] - 75s 202ms/step - loss: 0.6464 - acc: 0.8072 - lr: 6.8766e-04\n",
            "\n",
            "Epoch 35: LearningRateScheduler setting learning rate to 0.0007408768370508576.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 35/100\n",
            "370/370 [==============================] - 75s 204ms/step - loss: 0.6256 - acc: 0.8141 - lr: 6.7138e-04\n",
            "\n",
            "Epoch 36: LearningRateScheduler setting learning rate to 0.0007269952498697733.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 36/100\n",
            "370/370 [==============================] - 75s 203ms/step - loss: 0.5924 - acc: 0.8219 - lr: 6.5490e-04\n",
            "\n",
            "Epoch 37: LearningRateScheduler setting learning rate to 0.0007128896457825364.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 37/100\n",
            "370/370 [==============================] - 75s 204ms/step - loss: 0.5983 - acc: 0.8208 - lr: 6.3823e-04\n",
            "\n",
            "Epoch 38: LearningRateScheduler setting learning rate to 0.0006985739453173903.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 38/100\n",
            "370/370 [==============================] - 75s 202ms/step - loss: 0.5536 - acc: 0.8331 - lr: 6.2139e-04\n",
            "\n",
            "Epoch 39: LearningRateScheduler setting learning rate to 0.0006840622763423391.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 39/100\n",
            "370/370 [==============================] - 75s 204ms/step - loss: 0.5389 - acc: 0.8364 - lr: 6.0440e-04\n",
            "\n",
            "Epoch 40: LearningRateScheduler setting learning rate to 0.0006693689601226458.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 40/100\n",
            "370/370 [==============================] - 76s 205ms/step - loss: 0.4898 - acc: 0.8514 - lr: 5.8728e-04\n",
            "\n",
            "Epoch 41: LearningRateScheduler setting learning rate to 0.0006545084971874737.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 41/100\n",
            "370/370 [==============================] - 75s 203ms/step - loss: 0.4931 - acc: 0.8507 - lr: 5.7006e-04\n",
            "\n",
            "Epoch 42: LearningRateScheduler setting learning rate to 0.0006394955530196147.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 42/100\n",
            "370/370 [==============================] - 75s 202ms/step - loss: 0.4654 - acc: 0.8572 - lr: 5.5276e-04\n",
            "\n",
            "Epoch 43: LearningRateScheduler setting learning rate to 0.0006243449435824276.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 43/100\n",
            "370/370 [==============================] - 77s 208ms/step - loss: 0.4648 - acc: 0.8573 - lr: 5.3539e-04\n",
            "\n",
            "Epoch 44: LearningRateScheduler setting learning rate to 0.0006090716206982714.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 44/100\n",
            "370/370 [==============================] - 84s 228ms/step - loss: 0.4632 - acc: 0.8578 - lr: 5.1798e-04\n",
            "\n",
            "Epoch 45: LearningRateScheduler setting learning rate to 0.0005936906572928624.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 45/100\n",
            "370/370 [==============================] - 83s 225ms/step - loss: 0.4205 - acc: 0.8689 - lr: 5.0055e-04\n",
            "\n",
            "Epoch 46: LearningRateScheduler setting learning rate to 0.0005782172325201155.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 46/100\n",
            "370/370 [==============================] - 99s 267ms/step - loss: 0.4015 - acc: 0.8759 - lr: 4.8311e-04\n",
            "\n",
            "Epoch 47: LearningRateScheduler setting learning rate to 0.0005626666167821521.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 47/100\n",
            "370/370 [==============================] - 110s 296ms/step - loss: 0.3691 - acc: 0.8857 - lr: 4.6570e-04\n",
            "\n",
            "Epoch 48: LearningRateScheduler setting learning rate to 0.0005470541566592572.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 48/100\n",
            "370/370 [==============================] - 115s 312ms/step - loss: 0.3599 - acc: 0.8878 - lr: 4.4833e-04\n",
            "\n",
            "Epoch 49: LearningRateScheduler setting learning rate to 0.0005313952597646568.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 49/100\n",
            "370/370 [==============================] - 116s 314ms/step - loss: 0.3532 - acc: 0.8899 - lr: 4.3103e-04\n",
            "\n",
            "Epoch 50: LearningRateScheduler setting learning rate to 0.0005157053795390641.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 50/100\n",
            "370/370 [==============================] - 111s 299ms/step - loss: 0.3349 - acc: 0.8954 - lr: 4.1381e-04\n",
            "\n",
            "Epoch 51: LearningRateScheduler setting learning rate to 0.0005.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 51/100\n",
            "370/370 [==============================] - 112s 302ms/step - loss: 0.3378 - acc: 0.8940 - lr: 3.9669e-04\n",
            "\n",
            "Epoch 52: LearningRateScheduler setting learning rate to 0.00048429462046093585.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 52/100\n",
            "370/370 [==============================] - 112s 303ms/step - loss: 0.3192 - acc: 0.8997 - lr: 3.7971e-04\n",
            "\n",
            "Epoch 53: LearningRateScheduler setting learning rate to 0.0004686047402353433.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 53/100\n",
            "370/370 [==============================] - 111s 300ms/step - loss: 0.2899 - acc: 0.9088 - lr: 3.6286e-04\n",
            "\n",
            "Epoch 54: LearningRateScheduler setting learning rate to 0.00045294584334074284.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 54/100\n",
            "370/370 [==============================] - 111s 299ms/step - loss: 0.2945 - acc: 0.9075 - lr: 3.4619e-04\n",
            "\n",
            "Epoch 55: LearningRateScheduler setting learning rate to 0.00043733338321784784.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 55/100\n",
            "370/370 [==============================] - 111s 300ms/step - loss: 0.2710 - acc: 0.9150 - lr: 3.2971e-04\n",
            "\n",
            "Epoch 56: LearningRateScheduler setting learning rate to 0.0004217827674798845.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 56/100\n",
            "370/370 [==============================] - 110s 297ms/step - loss: 0.2786 - acc: 0.9124 - lr: 3.1343e-04\n",
            "\n",
            "Epoch 57: LearningRateScheduler setting learning rate to 0.0004063093427071376.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 57/100\n",
            "370/370 [==============================] - 113s 305ms/step - loss: 0.2688 - acc: 0.9149 - lr: 2.9738e-04\n",
            "\n",
            "Epoch 58: LearningRateScheduler setting learning rate to 0.0003909283793017289.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 58/100\n",
            "370/370 [==============================] - 114s 308ms/step - loss: 0.2523 - acc: 0.9214 - lr: 2.8158e-04\n",
            "\n",
            "Epoch 59: LearningRateScheduler setting learning rate to 0.0003756550564175727.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 59/100\n",
            "370/370 [==============================] - 113s 307ms/step - loss: 0.2271 - acc: 0.9295 - lr: 2.6604e-04\n",
            "\n",
            "Epoch 60: LearningRateScheduler setting learning rate to 0.0003605044469803854.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 60/100\n",
            "370/370 [==============================] - 123s 332ms/step - loss: 0.2251 - acc: 0.9292 - lr: 2.5079e-04\n",
            "\n",
            "Epoch 61: LearningRateScheduler setting learning rate to 0.00034549150281252633.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 61/100\n",
            "370/370 [==============================] - 113s 307ms/step - loss: 0.2156 - acc: 0.9323 - lr: 2.3585e-04\n",
            "\n",
            "Epoch 62: LearningRateScheduler setting learning rate to 0.0003306310398773543.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 62/100\n",
            "370/370 [==============================] - 109s 295ms/step - loss: 0.2051 - acc: 0.9358 - lr: 2.2122e-04\n",
            "\n",
            "Epoch 63: LearningRateScheduler setting learning rate to 0.00031593772365766105.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 63/100\n",
            "370/370 [==============================] - 114s 307ms/step - loss: 0.2012 - acc: 0.9373 - lr: 2.0694e-04\n",
            "\n",
            "Epoch 64: LearningRateScheduler setting learning rate to 0.00030142605468260977.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 64/100\n",
            "370/370 [==============================] - 114s 308ms/step - loss: 0.2016 - acc: 0.9371 - lr: 1.9301e-04\n",
            "\n",
            "Epoch 65: LearningRateScheduler setting learning rate to 0.00028711035421746366.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 65/100\n",
            "370/370 [==============================] - 113s 304ms/step - loss: 0.1863 - acc: 0.9422 - lr: 1.7946e-04\n",
            "\n",
            "Epoch 66: LearningRateScheduler setting learning rate to 0.00027300475013022663.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 66/100\n",
            "370/370 [==============================] - 109s 294ms/step - loss: 0.1793 - acc: 0.9454 - lr: 1.6630e-04\n",
            "\n",
            "Epoch 67: LearningRateScheduler setting learning rate to 0.0002591231629491423.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 67/100\n",
            "370/370 [==============================] - 109s 294ms/step - loss: 0.1686 - acc: 0.9484 - lr: 1.5355e-04\n",
            "\n",
            "Epoch 68: LearningRateScheduler setting learning rate to 0.00024547929212481435.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 68/100\n",
            "370/370 [==============================] - 110s 298ms/step - loss: 0.1685 - acc: 0.9480 - lr: 1.4122e-04\n",
            "\n",
            "Epoch 69: LearningRateScheduler setting learning rate to 0.00023208660251050156.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 69/100\n",
            "370/370 [==============================] - 111s 299ms/step - loss: 0.1625 - acc: 0.9505 - lr: 1.2933e-04\n",
            "\n",
            "Epoch 70: LearningRateScheduler setting learning rate to 0.0002189583110739348.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 70/100\n",
            "370/370 [==============================] - 113s 306ms/step - loss: 0.1583 - acc: 0.9521 - lr: 1.1789e-04\n",
            "\n",
            "Epoch 71: LearningRateScheduler setting learning rate to 0.00020610737385376348.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 71/100\n",
            "370/370 [==============================] - 109s 294ms/step - loss: 0.1521 - acc: 0.9541 - lr: 1.0692e-04\n",
            "\n",
            "Epoch 72: LearningRateScheduler setting learning rate to 0.00019354647317351188.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 72/100\n",
            "370/370 [==============================] - 107s 289ms/step - loss: 0.1425 - acc: 0.9576 - lr: 9.6424e-05\n",
            "\n",
            "Epoch 73: LearningRateScheduler setting learning rate to 0.00018128800512565513.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 73/100\n",
            "370/370 [==============================] - 107s 289ms/step - loss: 0.1389 - acc: 0.9588 - lr: 8.6422e-05\n",
            "\n",
            "Epoch 74: LearningRateScheduler setting learning rate to 0.00016934406733817414.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 74/100\n",
            "370/370 [==============================] - 107s 290ms/step - loss: 0.1391 - acc: 0.9583 - lr: 7.6925e-05\n",
            "\n",
            "Epoch 75: LearningRateScheduler setting learning rate to 0.00015772644703565563.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 75/100\n",
            "370/370 [==============================] - 107s 288ms/step - loss: 0.1353 - acc: 0.9598 - lr: 6.7944e-05\n",
            "\n",
            "Epoch 76: LearningRateScheduler setting learning rate to 0.00014644660940672628.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 76/100\n",
            "370/370 [==============================] - 107s 289ms/step - loss: 0.1341 - acc: 0.9594 - lr: 5.9490e-05\n",
            "\n",
            "Epoch 77: LearningRateScheduler setting learning rate to 0.00013551568628929433.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 77/100\n",
            "370/370 [==============================] - 108s 291ms/step - loss: 0.1269 - acc: 0.9637 - lr: 5.1573e-05\n",
            "\n",
            "Epoch 78: LearningRateScheduler setting learning rate to 0.00012494446518477025.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 78/100\n",
            "370/370 [==============================] - 107s 289ms/step - loss: 0.1265 - acc: 0.9625 - lr: 4.4203e-05\n",
            "\n",
            "Epoch 79: LearningRateScheduler setting learning rate to 0.00011474337861210544.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 79/100\n",
            "370/370 [==============================] - 107s 289ms/step - loss: 0.1249 - acc: 0.9635 - lr: 3.7389e-05\n",
            "\n",
            "Epoch 80: LearningRateScheduler setting learning rate to 0.00010492249381215479.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 80/100\n",
            "370/370 [==============================] - 107s 290ms/step - loss: 0.1224 - acc: 0.9642 - lr: 3.1140e-05\n",
            "\n",
            "Epoch 81: LearningRateScheduler setting learning rate to 9.549150281252633e-05.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 81/100\n",
            "370/370 [==============================] - 107s 289ms/step - loss: 0.1190 - acc: 0.9656 - lr: 2.5462e-05\n",
            "\n",
            "Epoch 82: LearningRateScheduler setting learning rate to 8.645971286271903e-05.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 82/100\n",
            "370/370 [==============================] - 112s 304ms/step - loss: 0.1195 - acc: 0.9653 - lr: 2.0363e-05\n",
            "\n",
            "Epoch 83: LearningRateScheduler setting learning rate to 7.783603724899258e-05.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 83/100\n",
            "370/370 [==============================] - 113s 306ms/step - loss: 0.1159 - acc: 0.9672 - lr: 1.5849e-05\n",
            "\n",
            "Epoch 84: LearningRateScheduler setting learning rate to 6.962898649802824e-05.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 84/100\n",
            "370/370 [==============================] - 111s 301ms/step - loss: 0.1168 - acc: 0.9664 - lr: 1.1925e-05\n",
            "\n",
            "Epoch 85: LearningRateScheduler setting learning rate to 6.184665997806827e-05.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 85/100\n",
            "370/370 [==============================] - 110s 297ms/step - loss: 0.1148 - acc: 0.9667 - lr: 8.5967e-06\n",
            "\n",
            "Epoch 86: LearningRateScheduler setting learning rate to 5.449673790581611e-05.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 86/100\n",
            "370/370 [==============================] - 113s 306ms/step - loss: 0.1133 - acc: 0.9678 - lr: 5.8677e-06\n",
            "\n",
            "Epoch 87: LearningRateScheduler setting learning rate to 4.758647376699032e-05.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 87/100\n",
            "370/370 [==============================] - 109s 294ms/step - loss: 0.1118 - acc: 0.9688 - lr: 3.7412e-06\n",
            "\n",
            "Epoch 88: LearningRateScheduler setting learning rate to 4.112268715800943e-05.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 88/100\n",
            "370/370 [==============================] - 111s 301ms/step - loss: 0.1129 - acc: 0.9680 - lr: 2.2200e-06\n",
            "\n",
            "Epoch 89: LearningRateScheduler setting learning rate to 3.5111757055874326e-05.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 89/100\n",
            "370/370 [==============================] - 110s 298ms/step - loss: 0.1134 - acc: 0.9674 - lr: 1.3059e-06\n",
            "\n",
            "Epoch 90: LearningRateScheduler setting learning rate to 2.9559615522887274e-05.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 90/100\n",
            "370/370 [==============================] - 110s 298ms/step - loss: 0.1134 - acc: 0.9677 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 91: LearningRateScheduler setting learning rate to 2.4471741852423235e-05.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 91/100\n",
            "370/370 [==============================] - 110s 298ms/step - loss: 0.1123 - acc: 0.9672 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 92: LearningRateScheduler setting learning rate to 1.985315716152847e-05.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 92/100\n",
            "370/370 [==============================] - 110s 297ms/step - loss: 0.1121 - acc: 0.9687 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 93: LearningRateScheduler setting learning rate to 1.5708419435684463e-05.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 93/100\n",
            "370/370 [==============================] - 110s 297ms/step - loss: 0.1112 - acc: 0.9687 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 94: LearningRateScheduler setting learning rate to 1.2041619030626282e-05.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 94/100\n",
            "370/370 [==============================] - 112s 304ms/step - loss: 0.1128 - acc: 0.9680 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 95: LearningRateScheduler setting learning rate to 8.856374635655695e-06.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 95/100\n",
            "370/370 [==============================] - 111s 299ms/step - loss: 0.1137 - acc: 0.9678 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 96: LearningRateScheduler setting learning rate to 6.15582970243117e-06.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 96/100\n",
            "370/370 [==============================] - 110s 297ms/step - loss: 0.1114 - acc: 0.9685 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 97: LearningRateScheduler setting learning rate to 3.942649342761117e-06.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 97/100\n",
            "370/370 [==============================] - 115s 311ms/step - loss: 0.1129 - acc: 0.9684 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 98: LearningRateScheduler setting learning rate to 2.219017698460002e-06.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 98/100\n",
            "370/370 [==============================] - 111s 301ms/step - loss: 0.1117 - acc: 0.9682 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 99: LearningRateScheduler setting learning rate to 9.866357858642206e-07.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 99/100\n",
            "370/370 [==============================] - 116s 314ms/step - loss: 0.1107 - acc: 0.9688 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 100: LearningRateScheduler setting learning rate to 2.467198171342e-07.\n",
            "learning rate: 2.47e-07, weight decay: 1.23e-08\n",
            "Epoch 100/100\n",
            "370/370 [==============================] - 111s 301ms/step - loss: 0.1120 - acc: 0.9677 - lr: 1.0000e-06\n"
          ]
        }
      ],
      "source": [
        "if cfg.TRAIN_MODEL:\n",
        "    history = model_two.fit(\n",
        "        X, y,\n",
        "        epochs=cfg.EPOCHS, \n",
        "        batch_size=cfg.BATCH_SIZE,\n",
        "        callbacks=callbacks, \n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [],
      "source": [
        "del X; del y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [],
      "source": [
        "if cfg.TRAIN_MODEL:\n",
        "    model_two.save_weights(DATA_DIR/'final_model_two.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_two.load_weights('D:/New folder/final_model_two.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "285/285 [==============================] - 5s 16ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.005484861781483106"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_val_pred = model_two.predict(x_test).argmax(axis=1)\n",
        "np.mean(y_test == y_val_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [],
      "source": [
        "asl_model = keras.models.load_model(DATA_DIR/'asl_model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "84\n",
            "5796\n"
          ]
        }
      ],
      "source": [
        "ROWS_PER_FRAME = 543\n",
        "LANDMARK_IDX = [0,9,11,13,14,17,117,118,119,199,346,347,348] + list(range(468,543))\n",
        "DROP_Z = False\n",
        "\n",
        "NUM_FRAMES = 15\n",
        "SEGMENTS = 3\n",
        "\n",
        "LEFT_HAND_OFFSET = 468\n",
        "POSE_OFFSET = LEFT_HAND_OFFSET+21\n",
        "RIGHT_HAND_OFFSET = POSE_OFFSET+33\n",
        "\n",
        "## average over the entire face, and the entire 'pose'\n",
        "averaging_sets = [[0, 468], [POSE_OFFSET, 33]]\n",
        "\n",
        "lip_landmarks = [61, 185, 40, 39, 37,  0, 267, 269, 270, 409,\n",
        "                 291,146, 91,181, 84, 17, 314, 405, 321, 375, \n",
        "                 78, 191, 80, 81, 82, 13, 312, 311, 310, 415, \n",
        "                 95, 88, 178, 87, 14,317, 402, 318, 324, 308]\n",
        "left_hand_landmarks = list(range(LEFT_HAND_OFFSET, LEFT_HAND_OFFSET+21))\n",
        "right_hand_landmarks = list(range(RIGHT_HAND_OFFSET, RIGHT_HAND_OFFSET+21))\n",
        "\n",
        "point_landmarks = [item for sublist in [lip_landmarks, left_hand_landmarks, right_hand_landmarks] for item in sublist]\n",
        "\n",
        "LANDMARKS = len(point_landmarks) + len(averaging_sets)\n",
        "print(LANDMARKS)\n",
        "if DROP_Z:\n",
        "    INPUT_SHAPE1 = (NUM_FRAMES,LANDMARKS*2)\n",
        "else:\n",
        "    INPUT_SHAPE1 = (NUM_FRAMES,LANDMARKS*3)\n",
        "\n",
        "FLAT_INPUT_SHAPE = (INPUT_SHAPE1[0] + 2 * (SEGMENTS + 1)) * INPUT_SHAPE1[1]\n",
        "print(FLAT_INPUT_SHAPE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TensorShape([1, 5796])"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def tf_nan_mean(x, axis=0):\n",
        "    return tf.reduce_sum(tf.where(tf.math.is_nan(x), tf.zeros_like(x), x), axis=axis) / tf.reduce_sum(tf.where(tf.math.is_nan(x), tf.zeros_like(x), tf.ones_like(x)), axis=axis)\n",
        "\n",
        "def tf_nan_std(x, axis=0):\n",
        "    d = x - tf_nan_mean(x, axis=axis)\n",
        "    return tf.math.sqrt(tf_nan_mean(d * d, axis=axis))\n",
        "\n",
        "def flatten_means_and_stds1(x, axis=0):\n",
        "    # Get means and stds\n",
        "    x_mean = tf_nan_mean(x, axis=0)\n",
        "    x_std  = tf_nan_std(x,  axis=0)\n",
        "\n",
        "    x_out = tf.concat([x_mean, x_std], axis=0)\n",
        "    x_out = tf.reshape(x_out, (1, INPUT_SHAPE1[1]*2))\n",
        "    x_out = tf.where(tf.math.is_finite(x_out), x_out, tf.zeros_like(x_out))\n",
        "    return x_out\n",
        "\n",
        "class FeatureGen_2(tf.keras.layers.Layer):\n",
        "    def __init__(self):\n",
        "        super(FeatureGen_2, self).__init__()\n",
        "    \n",
        "    def call(self, x_in):\n",
        "        if DROP_Z:\n",
        "            x_in = x_in[:, :, 0:2]\n",
        "        x_list = [tf.expand_dims(tf_nan_mean(x_in[:, av_set[0]:av_set[0]+av_set[1], :], axis=1), axis=1) for av_set in averaging_sets]\n",
        "        x_list.append(tf.gather(x_in, point_landmarks, axis=1))\n",
        "        x = tf.concat(x_list, 1)\n",
        "\n",
        "        x_padded = x\n",
        "        for i in range(SEGMENTS):\n",
        "            p0 = tf.where( ((tf.shape(x_padded)[0] % SEGMENTS) > 0) & ((i % 2) != 0) , 1, 0)\n",
        "            p1 = tf.where( ((tf.shape(x_padded)[0] % SEGMENTS) > 0) & ((i % 2) == 0) , 1, 0)\n",
        "            paddings = [[p0, p1], [0, 0], [0, 0]]\n",
        "            x_padded = tf.pad(x_padded, paddings, mode=\"SYMMETRIC\")\n",
        "        x_list = tf.split(x_padded, SEGMENTS)\n",
        "        x_list = [flatten_means_and_stds1(_x, axis=0) for _x in x_list]\n",
        "\n",
        "        x_list.append(flatten_means_and_stds1(x, axis=0))\n",
        "        \n",
        "        ## Resize only dimension 0. Resize can't handle nan, so replace nan with that dimension's avg value to reduce impact.\n",
        "        x = tf.image.resize(tf.where(tf.math.is_finite(x), x, tf_nan_mean(x, axis=0)), [NUM_FRAMES, LANDMARKS])\n",
        "        x = tf.reshape(x, (1, INPUT_SHAPE1[0]*INPUT_SHAPE1[1]))\n",
        "        x = tf.where(tf.math.is_nan(x), tf.zeros_like(x), x)\n",
        "        x_list.append(x)\n",
        "        x = tf.concat(x_list, axis=1)\n",
        "        return x\n",
        "#print(FeatureGen_2()(tf.keras.Input((543, 3), dtype=tf.float32, name=\"inputs\")))\n",
        "#FeatureGen_2()(load_relevant_data_subset(train_df.path[0]))\n",
        "feature_gen2 = FeatureGen_2()\n",
        "feature_gen2(load_relevant_data_subset(DATA_DIR/train.path[0])).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [],
      "source": [
        "class FinalModel(tf.keras.Model):\n",
        "    def __init__(self, model_1, model_2, model_3, pp_layer_1, pp_layer_2, pp_layer_3):\n",
        "        super().__init__()\n",
        "        self.model_1 = model_1\n",
        "        self.model_2 = model_2\n",
        "        self.model_3 = model_3\n",
        "        self.pp_layer_1 =  pp_layer_1\n",
        "        self.pp_layer_2 = pp_layer_2\n",
        "        self.pp_layer_3 = pp_layer_3\n",
        "\n",
        "    @tf.function(input_signature=[tf.TensorSpec(shape=[None, cfg.N_ROWS, cfg.N_DIMS], dtype=tf.float32, name='inputs')])        \n",
        "    def __call__(self, inputs):\n",
        "        #model-2 (transformer)\n",
        "        x, non_empty_frame_idxs = self.pp_layer_2(inputs)\n",
        "        x = tf.expand_dims(x, axis=0)\n",
        "        non_empty_frame_idxs = tf.expand_dims(non_empty_frame_idxs, axis=0)\n",
        "        _outputs_2 = self.model_2({ 'frames': x, 'non_empty_frame_idxs': non_empty_frame_idxs })\n",
        "        _outputs_2 = tf.squeeze(_outputs_2, axis=0)\n",
        "        \n",
        "        # model-1 (custom)\n",
        "        x = self.pp_layer_1(tf.cast(inputs, dtype=tf.float32))\n",
        "        _outputs_1 = self.model_1(x)[0, :]\n",
        "        \n",
        "        # model-3 (custom)\n",
        "        x = self.pp_layer_3(tf.cast(inputs, dtype=tf.float32))\n",
        "        _outputs_3 = self.model_3(x)[0, :]\n",
        "        \n",
        "        outputs = (0.7 * _outputs_2) + ((0.60* _outputs_3)+(0.30* _outputs_1))/3\n",
        "  \n",
        "        return {'outputs': outputs}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [],
      "source": [
        "final_model = FinalModel(model_two, model_one, asl_model, feature_gen1,preprocess_layer, feature_gen2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<keras.engine.functional.Functional at 0x1f8c6119a80>,\n",
              " <keras.engine.functional.Functional at 0x1f7d8417370>,\n",
              " <keras.engine.functional.Functional at 0x1f8a56e7520>,\n",
              " <__main__.FeatureGen_1 at 0x1f8a57281f0>,\n",
              " <__main__.PreprocessLayer at 0x1f7d77e0100>,\n",
              " <__main__.FeatureGen_2 at 0x1f8a56e7a90>]"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "final_model.layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "demo_prediction: 232, correct: 232\n"
          ]
        }
      ],
      "source": [
        "demo_raw_data = load_relevant_data_subset(DATA_DIR/train['path'].values[1])\n",
        "demo_output = final_model(demo_raw_data)[\"outputs\"]\n",
        "demo_prediction = demo_output.numpy().argmax()\n",
        "print(f'demo_prediction: {demo_prediction}, correct: {train.iloc[1][\"sign_ord\"]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_parquet(DATA_DIR/train.path[0])\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_drawing_styles = mp.solutions.drawing_styles\n",
        "mp_hands = mp.solutions.hands\n",
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "mp_holistic = mp.solutions.holistic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_frame_landmark_df(results,frame):\n",
        "    df_skel = df[['type','landmark_index']].drop_duplicates().reset_index(drop=True).copy()\n",
        "    face = pd.DataFrame()\n",
        "    pose = pd.DataFrame()\n",
        "    left_hand = pd.DataFrame()\n",
        "    right_hand =pd.DataFrame()\n",
        "\n",
        "    if results.face_landmarks:\n",
        "        for i, point in enumerate(results.face_landmarks.landmark):\n",
        "            face.loc[i,['x','y','z']] = [point.x,point.y,point.z]\n",
        "    if results.pose_landmarks:\n",
        "        for i, point in enumerate(results.pose_landmarks.landmark):\n",
        "            pose.loc[i,['x','y','z']] = [point.x,point.y,point.z]\n",
        "    if results.left_hand_landmarks:\n",
        "        for i, point in enumerate(results.left_hand_landmarks.landmark):\n",
        "            left_hand.loc[i,['x','y','z']] = [point.x,point.y,point.z]\n",
        "    if results.right_hand_landmarks:\n",
        "        for i, point in enumerate(results.right_hand_landmarks.landmark):\n",
        "            right_hand.loc[i,['x','y','z']] = [point.x,point.y,point.z]\n",
        "            \n",
        "    face = face.reset_index().rename(columns={'index':'landmark_index'}).assign(type='face')\n",
        "    pose = pose.reset_index().rename(columns={'index':'landmark_index'}).assign(type='pose')\n",
        "    left_hand = left_hand.reset_index().rename(columns={'index':'landmark_index'}).assign(type='left_hand')\n",
        "    right_hand = right_hand.reset_index().rename(columns={'index':'landmark_index'}).assign(type='right_hand')\n",
        "\n",
        "    landmarks = pd.concat([face,pose,left_hand,right_hand]).reset_index(drop=True)\n",
        "    landmarks =  df_skel.merge(landmarks, on = ['type','landmark_index'], how = 'left')\n",
        "    landmarks = landmarks.assign(frame=frame)\n",
        "    return landmarks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def do_capture_loop():\n",
        "    all_landmarks = []    \n",
        "    cap = cv2.VideoCapture(0)\n",
        "    with mp_holistic.Holistic(\n",
        "        min_detection_confidence=0.5,\n",
        "        min_tracking_confidence=0.5\n",
        "    ) as holistic:\n",
        "        frame = 0\n",
        "        while cap.isOpened():\n",
        "            frame +=1\n",
        "            success,image = cap.read()\n",
        "            if not success:\n",
        "                print(\"Ignoring empty camera frame\")\n",
        "                continue\n",
        "            image.flags.writeable = False\n",
        "            image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
        "            results = holistic.process(image)\n",
        "            #Create landmark dataframe\n",
        "            landmarks = create_frame_landmark_df(results,frame)\n",
        "            all_landmarks.append(landmarks)\n",
        "            image.flags.writeable = True\n",
        "            image = cv2.cvtColor(image,cv2.COLOR_RGB2BGR)\n",
        "            mp_drawing.draw_landmarks(\n",
        "                image,\n",
        "                results.face_landmarks,\n",
        "                mp_holistic.FACEMESH_CONTOURS,\n",
        "                landmark_drawing_spec=None,\n",
        "                connection_drawing_spec=mp_drawing_styles\n",
        "                .get_default_face_mesh_contours_style())\n",
        "            mp_drawing.draw_landmarks(\n",
        "                image,\n",
        "                results.pose_landmarks,\n",
        "                mp_holistic.POSE_CONNECTIONS,\n",
        "                landmark_drawing_spec=mp_drawing_styles\n",
        "                .get_default_pose_landmarks_style())\n",
        "            cv2.imshow('MediaPipe Holistic',cv2.flip(image,1))\n",
        "            if cv2.waitKey(5) & 0xFF == 27:\n",
        "                cap.release()\n",
        "                cv2.destroyAllWindows()\n",
        "                break\n",
        "    return all_landmarks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "landmarks = do_capture_loop()\n",
        "landmarks = pd.concat(landmarks).reset_index(drop=True).to_parquet(\"output_6.parquet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig = px.scatter_3d(face,x='x',y='y',z='z',size_max=1)\n",
        "fig.update_traces(marker_size=2.0)\n",
        "fig.show() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "194\n"
          ]
        }
      ],
      "source": [
        "raw_data = load_relevant_data_subset('D:/New folder/output_6.parquet')\n",
        "output = final_model(raw_data)[\"outputs\"]\n",
        "prediction = output.numpy().argmax()\n",
        "print(prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'shhh'"
            ]
          },
          "execution_count": 112,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "ORD2SIGN[prediction]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'tf' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m converter \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mlite\u001b[39m.\u001b[39mTFLiteConverter\u001b[39m.\u001b[39mfrom_keras_model(final_model)\n\u001b[0;32m      2\u001b[0m converter\u001b[39m.\u001b[39moptimizations \u001b[39m=\u001b[39m [tf\u001b[39m.\u001b[39mlite\u001b[39m.\u001b[39mOptimize\u001b[39m.\u001b[39mDEFAULT]\n\u001b[0;32m      3\u001b[0m tflite_model \u001b[39m=\u001b[39m converter\u001b[39m.\u001b[39mconvert()\n",
            "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
          ]
        }
      ],
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(final_model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_model = converter.convert()\n",
        "with open('./model.tflite', 'wb') as f:\n",
        "    f.write(tflite_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if cfg.TRAIN_MODEL:\n",
        "    final_model.save_weights('final_model.h5')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
